{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import panda and Numpy Packages\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.3\n"
     ]
    }
   ],
   "source": [
    "#Ex-1: print Panda version\n",
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    PLW\n",
      "1    CDR\n",
      "2    11B\n",
      "3    TEN\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Ex-2: Create series object and print\n",
    "stocks = ['PLW', 'CDR', '11B', 'TEN']\n",
    "print(pd.Series(data=stocks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLW    387.0\n",
      "CDR    339.5\n",
      "TEN    349.5\n",
      "11B    391.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Ex-3: Create series object and assign it to quotation object\n",
    "stocks = {'PLW': 387.00, 'CDR': 339.5, 'TEN': 349.5, '11B': 391.0}\n",
    "quotation = pd.Series(data=stocks)\n",
    "print(quotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[387.0, 339.5, 349.5, 391.0]\n"
     ]
    }
   ],
   "source": [
    "#Ex-4: Convert quoations to list\n",
    "stocks = {'PLW': 387.00, 'CDR': 339.5, 'TEN': 349.5, '11B': 391.0}\n",
    "quotations = pd.Series(data=stocks)\n",
    "quotations = quotations.tolist()\n",
    "print(quotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     price\n",
      "PLW  387.0\n",
      "CDR  339.5\n",
      "TEN  349.5\n",
      "11B  391.0\n"
     ]
    }
   ],
   "source": [
    "#Ex-5: Convert quotations to dataframe and set the column name to price\n",
    "stocks = {'PLW': 387.00, 'CDR': 339.5, 'TEN': 349.5, '11B': 391.0}\n",
    "quotations = pd.Series(data=stocks)\n",
    "quotations = pd.DataFrame(quotations, columns=[\"price\"])\n",
    "print(quotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10 20 30 40 50 60 70 80 90]\n",
      "[101 102 103 104 105 106 107 108 109]\n",
      "\n",
      "101    10.0\n",
      "102    20.0\n",
      "103    30.0\n",
      "104    40.0\n",
      "105    50.0\n",
      "106    60.0\n",
      "107    70.0\n",
      "108    80.0\n",
      "109    90.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Ex-6: Using Numpy and pandas Create series:\n",
    "data1 = np.arange(10,100,10)\n",
    "data2 = np.arange(101,110,1)\n",
    "print(data1)\n",
    "print(data2)\n",
    "print()\n",
    "res = pd.Series(data = data1, index=data2, dtype='float')\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    1\n",
      "b    2\n",
      "c    3\n",
      "d    4\n",
      "dtype: int32\n"
     ]
    }
   ],
   "source": [
    "#Ex-7: convert type to int\n",
    "series = pd.Series(['001', '002', '003', '004'], list('abcd'))\n",
    "series = series.astype(int)\n",
    "print(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    1\n",
      "b    2\n",
      "c    3\n",
      "d    4\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Ex-7: convert type to int\n",
    "series = pd.Series(['001', '002', '003', '004'], list('abcd'))\n",
    "series = pd.to_numeric(series)\n",
    "print(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLW    387.0\n",
      "CDR    339.5\n",
      "TEN    349.5\n",
      "11B    391.0\n",
      "BBT     25.5\n",
      "F51     19.2\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Ex-8: Add 2 elements to this series {'BBT': 25.5, 'F51': 19.2}\n",
    "stocks = {'PLW': 387.00, 'CDR': 339.5, 'TEN': 349.5, '11B': 391.0}\n",
    "quotations = pd.Series(data=stocks)\n",
    "quotations = quotations.append(pd.Series({'BBT': 25.5, 'F51': 19.2}))\n",
    "print(quotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ticker  price\n",
      "0    PLW  387.0\n",
      "1    CDR  339.5\n",
      "2    TEN  349.5\n",
      "3    11B  391.0\n",
      "4    BBT   25.5\n",
      "5    F51   19.2\n"
     ]
    }
   ],
   "source": [
    "#Ex-9: Reset index and name columns 'ticker' and 'price'\n",
    "stocks = {'PLW': 387.00, 'CDR': 339.5, 'TEN': 349.5, '11B': 391.0, 'BBT': 25.5, 'F51': 19.2}\n",
    "quotations = pd.Series(data=stocks)\n",
    "quotations = pd.DataFrame(quotations).reset_index()\n",
    "quotations.columns = ['ticker', 'price']\n",
    "print(quotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     company   price   ticker\n",
      "0     Amazon  2375.0  AMZN.US\n",
      "1  Microsoft   178.6  MSFT.US\n",
      "2   Facebook   179.2    FB.US\n"
     ]
    }
   ],
   "source": [
    "#Ex-10: Create following data object and assign it to company variable\n",
    "data_dict = {\n",
    "    'company': ['Amazon', 'Microsoft', 'Facebook'],\n",
    "    'price': [2375.00, 178.6, 179.2],\n",
    "    'ticker': ['AMZN.US', 'MSFT.US', 'FB.US']\n",
    "}\n",
    " \n",
    "companies = pd.DataFrame(data=data_dict)\n",
    "print(companies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            price   ticker\n",
      "company                   \n",
      "Amazon     2375.0  AMZN.US\n",
      "Microsoft   178.6  MSFT.US\n",
      "Facebook    179.2    FB.US\n"
     ]
    }
   ],
   "source": [
    "#Ex-11: Convert first column of above dataset to index\n",
    "data_dict = {\n",
    "    'company': ['Amazon', 'Microsoft', 'Facebook'],\n",
    "    'price': [2375.00, 178.6, 179.2],\n",
    "    'ticker': ['AMZN.US', 'MSFT.US', 'FB.US']\n",
    "}\n",
    " \n",
    "companies = pd.DataFrame(data=data_dict)\n",
    "companies = companies.set_index('company')\n",
    "print(companies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2020-01-01', '2020-01-02', '2020-01-03', '2020-01-04',\n",
      "               '2020-01-05', '2020-01-06', '2020-01-07', '2020-01-08',\n",
      "               '2020-01-09', '2020-01-10', '2020-01-11', '2020-01-12',\n",
      "               '2020-01-13', '2020-01-14', '2020-01-15', '2020-01-16',\n",
      "               '2020-01-17', '2020-01-18', '2020-01-19', '2020-01-20',\n",
      "               '2020-01-21', '2020-01-22', '2020-01-23', '2020-01-24',\n",
      "               '2020-01-25', '2020-01-26', '2020-01-27', '2020-01-28',\n",
      "               '2020-01-29', '2020-01-30', '2020-01-31'],\n",
      "              dtype='datetime64[ns]', freq='D')\n"
     ]
    }
   ],
   "source": [
    "#EX-12(A): Create Datetimeindex object containing the yyyy-mm-dd format for all days from Jan-2020 and assign it to date_range variable\n",
    "date_range = pd.date_range(start='2020-01-01', periods=31)\n",
    "print(date_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2020-01-01', '2020-01-02', '2020-01-03', '2020-01-04',\n",
      "               '2020-01-05', '2020-01-06', '2020-01-07', '2020-01-08',\n",
      "               '2020-01-09', '2020-01-10', '2020-01-11', '2020-01-12',\n",
      "               '2020-01-13', '2020-01-14', '2020-01-15', '2020-01-16',\n",
      "               '2020-01-17', '2020-01-18', '2020-01-19', '2020-01-20',\n",
      "               '2020-01-21', '2020-01-22', '2020-01-23', '2020-01-24',\n",
      "               '2020-01-25', '2020-01-26', '2020-01-27', '2020-01-28',\n",
      "               '2020-01-29', '2020-01-30', '2020-01-31'],\n",
      "              dtype='datetime64[ns]', freq='D')\n"
     ]
    }
   ],
   "source": [
    "#EX-12(B): Create Datetimeindex object containing the yyyy-mm-dd format for all days from Jan-2020 and assign it to date_range variable\n",
    "date_range = pd.date_range(start='2020-01-01', end='2020-01-31')\n",
    "print(date_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2020-01-06', '2020-01-13', '2020-01-20', '2020-01-27',\n",
      "               '2020-02-03', '2020-02-10', '2020-02-17', '2020-02-24',\n",
      "               '2020-03-02', '2020-03-09', '2020-03-16', '2020-03-23',\n",
      "               '2020-03-30', '2020-04-06', '2020-04-13', '2020-04-20',\n",
      "               '2020-04-27', '2020-05-04', '2020-05-11', '2020-05-18',\n",
      "               '2020-05-25', '2020-06-01', '2020-06-08', '2020-06-15',\n",
      "               '2020-06-22', '2020-06-29', '2020-07-06', '2020-07-13',\n",
      "               '2020-07-20', '2020-07-27', '2020-08-03', '2020-08-10',\n",
      "               '2020-08-17', '2020-08-24', '2020-08-31', '2020-09-07',\n",
      "               '2020-09-14', '2020-09-21', '2020-09-28', '2020-10-05',\n",
      "               '2020-10-12', '2020-10-19', '2020-10-26', '2020-11-02',\n",
      "               '2020-11-09', '2020-11-16', '2020-11-23', '2020-11-30',\n",
      "               '2020-12-07', '2020-12-14', '2020-12-21', '2020-12-28'],\n",
      "              dtype='datetime64[ns]', freq='W-MON')\n"
     ]
    }
   ],
   "source": [
    "#EX-13(A): Create Datetimeindex object containing the yyyy-mm-dd format for all Mondays from Jan-2020 and assign it to date_range variable\n",
    "date_range = pd.date_range(start='2020-01-01', periods=52, freq='W-MON')\n",
    "print(date_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2020-01-06', '2020-01-13', '2020-01-20', '2020-01-27',\n",
      "               '2020-02-03', '2020-02-10', '2020-02-17', '2020-02-24',\n",
      "               '2020-03-02', '2020-03-09', '2020-03-16', '2020-03-23',\n",
      "               '2020-03-30', '2020-04-06', '2020-04-13', '2020-04-20',\n",
      "               '2020-04-27', '2020-05-04', '2020-05-11', '2020-05-18',\n",
      "               '2020-05-25', '2020-06-01', '2020-06-08', '2020-06-15',\n",
      "               '2020-06-22', '2020-06-29', '2020-07-06', '2020-07-13',\n",
      "               '2020-07-20', '2020-07-27', '2020-08-03', '2020-08-10',\n",
      "               '2020-08-17', '2020-08-24', '2020-08-31', '2020-09-07',\n",
      "               '2020-09-14', '2020-09-21', '2020-09-28', '2020-10-05',\n",
      "               '2020-10-12', '2020-10-19', '2020-10-26', '2020-11-02',\n",
      "               '2020-11-09', '2020-11-16', '2020-11-23', '2020-11-30',\n",
      "               '2020-12-07', '2020-12-14', '2020-12-21', '2020-12-28'],\n",
      "              dtype='datetime64[ns]', freq='W-MON')\n"
     ]
    }
   ],
   "source": [
    "#EX-13(B): Create Datetimeindex object containing the yyyy-mm-dd format for all Mondays from Jan-2020 and assign it to date_range variable\n",
    "date_range = pd.date_range(start='2020-01-01', end='2020-12-31', freq='W-MON')\n",
    "print(date_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2021-01-01 00:00:00', '2021-01-01 01:00:00',\n",
      "               '2021-01-01 02:00:00', '2021-01-01 03:00:00',\n",
      "               '2021-01-01 04:00:00', '2021-01-01 05:00:00',\n",
      "               '2021-01-01 06:00:00', '2021-01-01 07:00:00',\n",
      "               '2021-01-01 08:00:00', '2021-01-01 09:00:00',\n",
      "               '2021-01-01 10:00:00', '2021-01-01 11:00:00',\n",
      "               '2021-01-01 12:00:00', '2021-01-01 13:00:00',\n",
      "               '2021-01-01 14:00:00', '2021-01-01 15:00:00',\n",
      "               '2021-01-01 16:00:00', '2021-01-01 17:00:00',\n",
      "               '2021-01-01 18:00:00', '2021-01-01 19:00:00',\n",
      "               '2021-01-01 20:00:00', '2021-01-01 21:00:00',\n",
      "               '2021-01-01 22:00:00', '2021-01-01 23:00:00'],\n",
      "              dtype='datetime64[ns]', freq='H')\n"
     ]
    }
   ],
   "source": [
    "#EX-14(A): Create Datetimeindex object containing the yyyy-mm-dd hh:mm:ss format for all Mondays from Jan-2020-01 with a time interval of 1h and assign it to date_range variable\n",
    "date_range = pd.date_range(start='2021-01-01', periods=24, freq='H')\n",
    "print(date_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2021-01-01 00:00:00', '2021-01-01 01:00:00',\n",
      "               '2021-01-01 02:00:00', '2021-01-01 03:00:00',\n",
      "               '2021-01-01 04:00:00', '2021-01-01 05:00:00',\n",
      "               '2021-01-01 06:00:00', '2021-01-01 07:00:00',\n",
      "               '2021-01-01 08:00:00', '2021-01-01 09:00:00',\n",
      "               '2021-01-01 10:00:00', '2021-01-01 11:00:00',\n",
      "               '2021-01-01 12:00:00', '2021-01-01 13:00:00',\n",
      "               '2021-01-01 14:00:00', '2021-01-01 15:00:00',\n",
      "               '2021-01-01 16:00:00', '2021-01-01 17:00:00',\n",
      "               '2021-01-01 18:00:00', '2021-01-01 19:00:00',\n",
      "               '2021-01-01 20:00:00', '2021-01-01 21:00:00',\n",
      "               '2021-01-01 22:00:00', '2021-01-01 23:00:00',\n",
      "               '2021-01-02 00:00:00'],\n",
      "              dtype='datetime64[ns]', freq='H')\n"
     ]
    }
   ],
   "source": [
    "#EX-14(B): Create Datetimeindex object containing the yyyy-mm-dd hh:mm:ss format for all Mondays from Jan-2020-01 with a time interval of 1h and assign it to date_range variable\n",
    "date_range = pd.date_range(start='2021-01-01', end='2021-01-02', freq='H')\n",
    "print(date_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          day  day_of_year\n",
      "0  2021-03-01           60\n",
      "1  2021-03-02           61\n",
      "2  2021-03-03           62\n",
      "3  2021-03-04           63\n",
      "4  2021-03-05           64\n",
      "5  2021-03-06           65\n",
      "6  2021-03-07           66\n",
      "7  2021-03-08           67\n",
      "8  2021-03-09           68\n",
      "9  2021-03-10           69\n",
      "10 2021-03-11           70\n",
      "11 2021-03-12           71\n",
      "12 2021-03-13           72\n",
      "13 2021-03-14           73\n",
      "14 2021-03-15           74\n",
      "15 2021-03-16           75\n",
      "16 2021-03-17           76\n",
      "17 2021-03-18           77\n",
      "18 2021-03-19           78\n",
      "19 2021-03-20           79\n",
      "20 2021-03-21           80\n",
      "21 2021-03-22           81\n",
      "22 2021-03-23           82\n",
      "23 2021-03-24           83\n",
      "24 2021-03-25           84\n",
      "25 2021-03-26           85\n",
      "26 2021-03-27           86\n",
      "27 2021-03-28           87\n",
      "28 2021-03-29           88\n",
      "29 2021-03-30           89\n",
      "30 2021-03-31           90\n"
     ]
    }
   ],
   "source": [
    "#EX-15: Create following dataframe object and print\n",
    "date_range = pd.date_range(start='2021-03-01', periods=31)\n",
    "df = pd.DataFrame(data=date_range, columns=['day'])\n",
    "df['day_of_year'] = df['day'].dt.dayofyear\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              normal   uniform  binomial\n",
      "2020-01-01  0.496714  0.167483         0\n",
      "2020-01-02 -0.138264  0.104568         0\n",
      "2020-01-03  0.647689  0.636430         0\n",
      "2020-01-04  1.523030  0.706476         0\n",
      "2020-01-05 -0.234153  0.031586         1\n",
      "...              ...       ...       ...\n",
      "2022-09-22 -0.281100  0.280683         1\n",
      "2022-09-23  1.797687  0.206993         0\n",
      "2022-09-24  0.640843  0.516573         0\n",
      "2022-09-25 -0.571179  0.005506         1\n",
      "2022-09-26  0.572583  0.007664         0\n",
      "\n",
      "[1000 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#EX-16: Create Dateframe Oject from given dictionary and assign it to df variable.As an index add date from 2020-01-01\n",
    "np.random.seed(42)\n",
    "data_dict = {\n",
    "    'normal': np.random.normal(loc=0, scale=1, size=1000),\n",
    "    'uniform': np.random.uniform(low=0, high=1, size=1000),\n",
    "    'binomial': np.random.binomial(n=1, p=0.2, size=1000)\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data=data_dict, index=pd.date_range('2020-01-01', periods=1000))\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              normal   uniform  binomial\n",
      "2020-01-01  0.496714  0.167483         0\n",
      "2020-01-02 -0.138264  0.104568         0\n",
      "2020-01-03  0.647689  0.636430         0\n",
      "2020-01-04  1.523030  0.706476         0\n",
      "2020-01-05 -0.234153  0.031586         1\n",
      "2020-01-06 -0.234137  0.936212         0\n",
      "2020-01-07  1.579213  0.051971         0\n",
      "2020-01-08  0.767435  0.541296         0\n",
      "2020-01-09 -0.469474  0.709061         1\n",
      "2020-01-10  0.542560  0.870969         0\n",
      "\n",
      "              normal   uniform  binomial\n",
      "2022-09-22 -0.281100  0.280683         1\n",
      "2022-09-23  1.797687  0.206993         0\n",
      "2022-09-24  0.640843  0.516573         0\n",
      "2022-09-25 -0.571179  0.005506         1\n",
      "2022-09-26  0.572583  0.007664         0\n"
     ]
    }
   ],
   "source": [
    "#EX-17: Print first 10 rows of this Dataframe then print blank line and print the last five rows of this object\n",
    "np.random.seed(42)\n",
    "data_dict = {\n",
    "    'normal': np.random.normal(loc=0, scale=1, size=1000),\n",
    "    'uniform': np.random.uniform(low=0, high=1, size=1000),\n",
    "    'binomial': np.random.binomial(n=1, p=0.2, size=1000)\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data=data_dict, index=pd.date_range('2020-01-01', periods=1000))\n",
    "print(df.head(10))\n",
    "print()\n",
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 1000 entries, 2020-01-01 to 2022-09-26\n",
      "Freq: D\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   normal    1000 non-null   float64\n",
      " 1   uniform   1000 non-null   float64\n",
      " 2   binomial  1000 non-null   int32  \n",
      "dtypes: float64(2), int32(1)\n",
      "memory usage: 27.3 KB\n",
      "None\n",
      "\n",
      "            normal      uniform    binomial\n",
      "count  1000.000000  1000.000000  1000.00000\n",
      "mean      0.019332     0.503649     0.19200\n",
      "std       0.979216     0.288357     0.39407\n",
      "min      -3.241267     0.003218     0.00000\n",
      "25%      -0.647590     0.247199     0.00000\n",
      "50%       0.025301     0.516126     0.00000\n",
      "75%       0.647944     0.746319     0.00000\n",
      "max       3.852731     0.999414     1.00000\n"
     ]
    }
   ],
   "source": [
    "#EX-18: Display basic information about df object using method, print blank line and print basic statistics of df method.\n",
    "np.random.seed(42)\n",
    "data_dict = {\n",
    "    'normal': np.random.normal(loc=0, scale=1, size=1000),\n",
    "    'uniform': np.random.uniform(low=0, high=1, size=1000),\n",
    "    'binomial': np.random.binomial(n=1, p=0.2, size=1000)\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data=data_dict, index=pd.date_range('2020-01-01', periods=1000))\n",
    "print(df.info())\n",
    "print()\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    808\n",
      "1    192\n",
      "Name: binomial, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#EX-19: Find the distribution of binomial column from this Dataframe\n",
    "np.random.seed(42)\n",
    "data_dict = {\n",
    "    'normal': np.random.normal(loc=0, scale=1, size=1000),\n",
    "    'uniform': np.random.uniform(low=0, high=1, size=1000),\n",
    "    'binomial': np.random.binomial(n=1, p=0.2, size=1000)\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data=data_dict, index=pd.date_range('2020-01-01', periods=1000))\n",
    "print(df['binomial'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              normal   uniform  binomial\n",
      "2020-01-01  0.496714  0.167483         0\n",
      "2020-01-02 -0.138264  0.104568         0\n",
      "2020-01-03  0.647689  0.636430         0\n",
      "2020-01-04  1.523030  0.706476         0\n",
      "2020-01-05 -0.234153  0.031586         1\n",
      "2020-01-06 -0.234137  0.936212         0\n",
      "2020-01-07  1.579213  0.051971         0\n",
      "2020-01-08  0.767435  0.541296         0\n",
      "2020-01-09 -0.469474  0.709061         1\n",
      "2020-01-10  0.542560  0.870969         0\n",
      "2020-01-11 -0.463418  0.714087         0\n",
      "2020-01-12 -0.465730  0.801728         0\n",
      "2020-01-13  0.241962  0.339450         0\n",
      "2020-01-14 -1.913280  0.814825         0\n",
      "2020-01-15 -1.724918  0.080115         0\n",
      "2020-01-16 -0.562288  0.894817         1\n",
      "2020-01-17 -1.012831  0.547592         0\n",
      "2020-01-18  0.314247  0.817298         0\n",
      "2020-01-19 -0.908024  0.452318         1\n",
      "2020-01-20 -1.412304  0.643578         0\n",
      "2020-01-21  1.465649  0.526403         0\n",
      "2020-01-22 -0.225776  0.731590         0\n",
      "2020-01-23  0.067528  0.081630         0\n",
      "2020-01-24 -1.424748  0.060352         0\n",
      "2020-01-25 -0.544383  0.247103         1\n",
      "2020-01-26  0.110923  0.159545         0\n",
      "2020-01-27 -1.150994  0.871784         0\n",
      "2020-01-28  0.375698  0.219214         0\n",
      "2020-01-29 -0.600639  0.975865         1\n",
      "2020-01-30 -0.291694  0.336896         1\n",
      "2020-01-31 -0.601707  0.182118         1\n",
      "2020-02-01  1.852278  0.789699         0\n",
      "2020-02-02 -0.013497  0.658708         0\n",
      "2020-02-03 -1.057711  0.498196         0\n",
      "2020-02-04  0.822545  0.555364         0\n",
      "2020-02-05 -1.220844  0.719202         0\n",
      "2020-02-06  0.208864  0.228455         0\n",
      "2020-02-07 -1.959670  0.996334         0\n",
      "2020-02-08 -1.328186  0.974793         0\n",
      "2020-02-09  0.196861  0.650326         0\n",
      "2020-02-10  0.738467  0.199542         0\n",
      "2020-02-11  0.171368  0.680228         0\n",
      "2020-02-12 -0.115648  0.072198         0\n",
      "2020-02-13 -0.301104  0.030653         0\n",
      "2020-02-14 -1.478522  0.257683         0\n",
      "2020-02-15 -0.719844  0.462623         0\n",
      "2020-02-16 -0.460639  0.868273         0\n",
      "2020-02-17  1.057122  0.727169         0\n",
      "2020-02-18  0.343618  0.742707         1\n",
      "2020-02-19 -1.763040  0.425493         0\n"
     ]
    }
   ],
   "source": [
    "#EX-20: Extract first 50 rows from the df object\n",
    "np.random.seed(42)\n",
    "data_dict = {\n",
    "    'normal': np.random.normal(loc=0, scale=1, size=1000),\n",
    "    'uniform': np.random.uniform(low=0, high=1, size=1000),\n",
    "    'binomial': np.random.binomial(n=1, p=0.2, size=1000)\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data=data_dict, index=pd.date_range('2020-01-01', periods=1000))\n",
    "print(df[:50])\n",
    "df.head(50).to_csv('dataframe50.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              normal   uniform  binomial\n",
      "2020-01-01  0.496714  0.167483         0\n",
      "2020-01-02 -0.138264  0.104568         0\n",
      "2020-01-03  0.647689  0.636430         0\n",
      "2020-01-04  1.523030  0.706476         0\n",
      "2020-01-05 -0.234153  0.031586         1\n",
      "2020-01-06 -0.234137  0.936212         0\n",
      "2020-01-07  1.579213  0.051971         0\n",
      "2020-01-08  0.767435  0.541296         0\n",
      "2020-01-09 -0.469474  0.709061         1\n",
      "2020-01-10  0.542560  0.870969         0\n"
     ]
    }
   ],
   "source": [
    "#EX-21: Load data from file dataframe50.csv\n",
    "df_new = pd.read_csv('dataframe50.csv', index_col=0)\n",
    "print(df_new[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date     Open     High        Low    Close   Volume\n",
      "0  2020-07-02  1451.84  1488.52  1451.0650  1469.93  2860915\n",
      "1  2020-07-01  1419.17  1448.48  1414.1800  1442.00  2109124\n",
      "2  2020-06-30  1396.88  1424.00  1386.9301  1418.05  2014320\n",
      "3  2020-06-29  1360.34  1398.00  1351.6500  1397.17  2253678\n",
      "4  2020-06-26  1432.63  1437.02  1355.0000  1362.54  4882014\n",
      "5  2020-06-25  1431.22  1442.32  1419.5401  1441.10  1197907\n",
      "6  2020-06-24  1463.28  1475.79  1430.0000  1432.70  1579579\n",
      "7  2020-06-23  1452.00  1475.20  1445.0000  1463.98  1887583\n",
      "8  2020-06-22  1425.01  1450.95  1419.1900  1450.66  1472072\n",
      "9  2020-06-19  1440.00  1444.50  1419.0000  1424.64  2639167\n"
     ]
    }
   ],
   "source": [
    "#EX-22:  Load data from file google.csv\n",
    "google = pd.read_csv('google.csv')\n",
    "print(google.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30 entries, 0 to 29\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Date    30 non-null     object \n",
      " 1   Open    30 non-null     float64\n",
      " 2   High    30 non-null     float64\n",
      " 3   Low     30 non-null     float64\n",
      " 4   Close   30 non-null     float64\n",
      " 5   Volume  30 non-null     int64  \n",
      "dtypes: float64(4), int64(1), object(1)\n",
      "memory usage: 1.5+ KB\n",
      "None\n",
      "\n",
      "              Open         High          Low        Close        Volume\n",
      "count    30.000000    30.000000    30.000000    30.000000  3.000000e+01\n",
      "mean   1428.889000  1445.470440  1412.767923  1430.681000  1.869471e+06\n",
      "std      22.943586    19.462454    24.728358    22.717075  7.014872e+05\n",
      "min    1360.340000  1398.000000  1351.650000  1362.540000  1.172069e+06\n",
      "25%    1419.377500  1436.802500  1396.565000  1418.097500  1.528364e+06\n",
      "50%    1431.925000  1444.805000  1419.095000  1433.820000  1.687518e+06\n",
      "75%    1444.605000  1452.628250  1428.301250  1445.430000  2.085423e+06\n",
      "max    1463.280000  1488.520000  1454.355000  1469.930000  4.882014e+06\n"
     ]
    }
   ],
   "source": [
    "#EX-23: Print basic information about google DataFrame, then print blank and print basic statistics from Dataframe\n",
    "google = pd.read_csv('google.csv')\n",
    "print(google.info())\n",
    "print()\n",
    "print(google.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Date     Open       High        Low    Close   Volume\n",
      "0   2020-07-02  1451.84  1488.5200  1451.0650  1469.93  2860915\n",
      "1   2020-07-01  1419.17  1448.4800  1414.1800  1442.00  2109124\n",
      "2   2020-06-30  1396.88  1424.0000  1386.9301  1418.05  2014320\n",
      "3   2020-06-29  1360.34  1398.0000  1351.6500  1397.17  2253678\n",
      "4   2020-06-26  1432.63  1437.0200  1355.0000  1362.54  4882014\n",
      "5   2020-06-25  1431.22  1442.3200  1419.5401  1441.10  1197907\n",
      "6   2020-06-24  1463.28  1475.7900  1430.0000  1432.70  1579579\n",
      "7   2020-06-23  1452.00  1475.2000  1445.0000  1463.98  1887583\n",
      "8   2020-06-22  1425.01  1450.9500  1419.1900  1450.66  1472072\n",
      "9   2020-06-19  1440.00  1444.5000  1419.0000  1424.64  2639167\n",
      "10  2020-06-18  1449.85  1452.9699  1426.2350  1434.12  1743071\n",
      "11  2020-06-17  1452.94  1462.2000  1435.1250  1452.54  1530500\n",
      "12  2020-06-16  1449.00  1457.1700  1428.9900  1446.47  1534826\n",
      "13  2020-06-15  1389.49  1425.0000  1387.1952  1420.74  1527652\n",
      "14  2020-06-12  1425.86  1434.5050  1385.8000  1412.92  1833756\n",
      "15  2020-06-11  1441.03  1451.6033  1398.4100  1401.90  2357243\n",
      "16  2020-06-10  1461.51  1472.7700  1454.3550  1464.70  1588116\n",
      "17  2020-06-09  1445.24  1467.8000  1442.3600  1452.08  1681155\n",
      "18  2020-06-08  1426.28  1449.0000  1424.4800  1448.04  1693881\n",
      "19  2020-06-05  1415.64  1446.3000  1407.6213  1440.02  2132350\n",
      "20  2020-06-04  1436.78  1441.3200  1406.0100  1414.30  1349105\n",
      "21  2020-06-03  1442.70  1449.0100  1431.6200  1439.25  1386640\n",
      "22  2020-06-02  1435.00  1443.0000  1421.6100  1442.31  1172069\n",
      "23  2020-06-01  1425.70  1441.5800  1422.2800  1434.87  1259254\n",
      "24  2020-05-29  1420.43  1436.7300  1415.9800  1433.52  1852522\n",
      "25  2020-05-28  1400.00  1444.4600  1399.0760  1418.24  1759787\n",
      "26  2020-05-27  1420.00  1425.3450  1394.6000  1420.28  1584185\n",
      "27  2020-05-26  1441.96  1445.1100  1419.3950  1421.37  2229488\n",
      "28  2020-05-22  1403.90  1417.0000  1395.9500  1413.24  1427206\n",
      "29  2020-05-21  1410.99  1416.4600  1394.3900  1406.75  1544976\n"
     ]
    }
   ],
   "source": [
    "#Ex-24: Convert index to the column Date assign changes to the google variable\n",
    "google = pd.read_csv('google.csv', index_col=0)\n",
    "google = google.reset_index()\n",
    "print(google)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date     Open     High        Low    Close   Volume  Year  Month\n",
      "0 2020-07-02  1451.84  1488.52  1451.0650  1469.93  2860915  2020      7\n",
      "1 2020-07-01  1419.17  1448.48  1414.1800  1442.00  2109124  2020      7\n",
      "2 2020-06-30  1396.88  1424.00  1386.9301  1418.05  2014320  2020      6\n",
      "3 2020-06-29  1360.34  1398.00  1351.6500  1397.17  2253678  2020      6\n",
      "4 2020-06-26  1432.63  1437.02  1355.0000  1362.54  4882014  2020      6\n"
     ]
    }
   ],
   "source": [
    "#EX-25: Assign 2 new columns A)Column with current month number named 'Month' B)Column with current year number named 'Year'\n",
    "google = pd.read_csv('google.csv', index_col=0)\n",
    "google = google.reset_index()\n",
    "google['Date'] = pd.to_datetime(google['Date'])\n",
    "google['Year'] = google['Date'].dt.year\n",
    "google['Month'] = google['Date'].dt.month\n",
    "print(google.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Month\n",
      "5    1418.900000\n",
      "6    1431.595455\n",
      "7    1455.965000\n",
      "Name: Close, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#EX-26: Compute the average closing price for the month (group data by month-the month column and then count the average value)\n",
    "google = pd.read_csv('google.csv', index_col=0)\n",
    "google = google.reset_index()\n",
    "google['Date'] = pd.to_datetime(google['Date'])\n",
    "google['Year'] = google['Date'].dt.year\n",
    "google['Month'] = google['Date'].dt.month\n",
    "print(google.groupby('Month')['Close'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date     Open     High     Low    Close   Volume\n",
      "4  2020-06-26  1432.63  1437.02  1355.0  1362.54  4882014\n"
     ]
    }
   ],
   "source": [
    "#EX-27: Find the index for which the close price has the lowest value and assign it to idx_min variable.Then extract the row for this index from the google DataFrame\n",
    "google = pd.read_csv('google.csv', index_col=0)\n",
    "google = google.reset_index()\n",
    "idx_min = google['Close'].argmin()\n",
    "\n",
    "print(google.iloc[[idx_min]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date     Open    Close   Volume\n",
      "0  2020-07-02  1451.84  1469.93  2860915\n",
      "1  2020-07-01  1419.17  1442.00  2109124\n",
      "2  2020-06-30  1396.88  1418.05  2014320\n",
      "3  2020-06-29  1360.34  1397.17  2253678\n",
      "4  2020-06-26  1432.63  1362.54  4882014\n"
     ]
    }
   ],
   "source": [
    "#EX-28: Extract the columns from google.csv (Date, Open, Close, Volume) \n",
    "\n",
    "google = pd.read_csv('google.csv', index_col=0)\n",
    "google = google.reset_index()\n",
    "print(google[['Date', 'Open', 'Close', 'Volume']].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Open     High        Low    Close   Volume\n",
      "Date                                                     \n",
      "2020-07-02  1451.84  1488.52  1451.0650  1469.93  2860915\n",
      "2020-07-01  1419.17  1448.48  1414.1800  1442.00  2109124\n",
      "2020-06-30  1396.88  1424.00  1386.9301  1418.05  2014320\n",
      "2020-06-29  1360.34  1398.00  1351.6500  1397.17  2253678\n",
      "2020-06-26  1432.63  1437.02  1355.0000  1362.54  4882014\n"
     ]
    }
   ],
   "source": [
    "#EX-29: Load data from google.csv. Set the index for the Date column and print this Dataframe\n",
    "google = pd.read_csv('google.csv')\n",
    "google = google.set_index('Date')\n",
    "print(google.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date     Open     High        Low    Close   Volume\n",
      "0 2020-07-02  1451.84  1488.52  1451.0650  1469.93  2860915\n",
      "1 2020-07-01  1419.17  1448.48  1414.1800  1442.00  2109124\n",
      "2 2020-06-30  1396.88  1424.00  1386.9301  1418.05  2014320\n",
      "3 2020-06-29  1360.34  1398.00  1351.6500  1397.17  2253678\n",
      "4 2020-06-26  1432.63  1437.02  1355.0000  1362.54  4882014\n"
     ]
    }
   ],
   "source": [
    "#Ex-30: Remove the Year and Month column from google Dataframe\n",
    "google = pd.read_csv('google.csv')\n",
    "google['Date'] = pd.to_datetime(google['Date'])\n",
    "google['Year'] = google['Date'].dt.year\n",
    "google['Month'] = google['Date'].dt.month\n",
    "google = google.drop(columns=['Year', 'Month'])\n",
    "print(google.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  O        H          L        C        V\n",
      "Date                                                     \n",
      "2020-07-02  1451.84  1488.52  1451.0650  1469.93  2860915\n",
      "2020-07-01  1419.17  1448.48  1414.1800  1442.00  2109124\n",
      "2020-06-30  1396.88  1424.00  1386.9301  1418.05  2014320\n",
      "2020-06-29  1360.34  1398.00  1351.6500  1397.17  2253678\n",
      "2020-06-26  1432.63  1437.02  1355.0000  1362.54  4882014\n"
     ]
    }
   ],
   "source": [
    "#Ex-31: Change the column name (Open-> O, High-H, Low-L,Close->C, Volume->V )\n",
    "google = pd.read_csv('google.csv', index_col=0)\n",
    "google.columns = ['O', 'H', 'L', 'C', 'V']\n",
    "print(google.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   customerID  gender  SeniorCitizen Partner Dependents  tenure PhoneService  \\\n",
      "0  7590-VHVEG  Female              0     Yes         No       1           No   \n",
      "1  5575-GNVDE    Male              0      No         No      34          Yes   \n",
      "\n",
      "      MultipleLines InternetService OnlineSecurity  ... DeviceProtection  \\\n",
      "0  No phone service             DSL             No  ...               No   \n",
      "1                No             DSL            Yes  ...              Yes   \n",
      "\n",
      "  TechSupport StreamingTV StreamingMovies        Contract PaperlessBilling  \\\n",
      "0          No          No              No  Month-to-month              Yes   \n",
      "1          No          No              No        One year               No   \n",
      "\n",
      "      PaymentMethod MonthlyCharges  TotalCharges Churn  \n",
      "0  Electronic check          29.85         29.85    No  \n",
      "1      Mailed check          56.95        1889.5    No  \n",
      "\n",
      "[2 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "#EX-32: Load this file into dataframes and assign it to df variable\n",
    "url = 'https://ml-repository-krakers.s3-eu-west-1.amazonaws.com/kaggle+/churn_modelling/Telco-Customer-Churn.csv'\n",
    "df = pd.read_csv(url)\n",
    "print(df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customerID          0\n",
      "gender              0\n",
      "SeniorCitizen       0\n",
      "Partner             0\n",
      "Dependents          0\n",
      "tenure              0\n",
      "PhoneService        0\n",
      "MultipleLines       0\n",
      "InternetService     0\n",
      "OnlineSecurity      0\n",
      "OnlineBackup        0\n",
      "DeviceProtection    0\n",
      "TechSupport         0\n",
      "StreamingTV         0\n",
      "StreamingMovies     0\n",
      "Contract            0\n",
      "PaperlessBilling    0\n",
      "PaymentMethod       0\n",
      "MonthlyCharges      0\n",
      "TotalCharges        0\n",
      "Churn               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#EX-33: Calculate the number of missing value for each variable\n",
    "url = 'https://ml-repository-krakers.s3-eu-west-1.amazonaws.com/kaggle+/churn_modelling/Telco-Customer-Churn.csv'\n",
    "df = pd.read_csv(url)\n",
    "missing_val = df.isnull().sum()\n",
    "print(missing_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1397.475    11\n",
      "20.200      11\n",
      "19.750       9\n",
      "19.650       8\n",
      "20.050       8\n",
      "            ..\n",
      "607.300      1\n",
      "1534.050     1\n",
      "1066.150     1\n",
      "249.950      1\n",
      "1024.000     1\n",
      "Name: TotalCharges, Length: 6531, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#EX-34: Try to replace missing value of TotalCharges column with its mean value\n",
    "url = 'https://ml-repository-krakers.s3-eu-west-1.amazonaws.com/kaggle+/churn_modelling/Telco-Customer-Churn.csv'\n",
    "df = pd.read_csv(url)\n",
    "TotalChargesMedian = df['TotalCharges'][df['TotalCharges'] != ' '].median() #Calculate the median of TotalCharges column\n",
    "df.loc[df['TotalCharges'] == ' ', 'TotalCharges'] = TotalChargesMedian #Fill the missing values with median\n",
    "df['TotalCharges'] = df['TotalCharges'].astype('float') #Convert TotalCharges column to float type\n",
    "print(df['TotalCharges'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 7043 entries, 7590-VHVEG to 3186-AJIEK\n",
      "Data columns (total 20 columns):\n",
      " #   Column            Non-Null Count  Dtype   \n",
      "---  ------            --------------  -----   \n",
      " 0   gender            7043 non-null   category\n",
      " 1   SeniorCitizen     7043 non-null   category\n",
      " 2   Partner           7043 non-null   category\n",
      " 3   Dependents        7043 non-null   category\n",
      " 4   tenure            7043 non-null   float64 \n",
      " 5   PhoneService      7043 non-null   category\n",
      " 6   MultipleLines     7043 non-null   category\n",
      " 7   InternetService   7043 non-null   category\n",
      " 8   OnlineSecurity    7043 non-null   category\n",
      " 9   OnlineBackup      7043 non-null   category\n",
      " 10  DeviceProtection  7043 non-null   category\n",
      " 11  TechSupport       7043 non-null   category\n",
      " 12  StreamingTV       7043 non-null   category\n",
      " 13  StreamingMovies   7043 non-null   category\n",
      " 14  Contract          7043 non-null   category\n",
      " 15  PaperlessBilling  7043 non-null   category\n",
      " 16  PaymentMethod     7043 non-null   category\n",
      " 17  MonthlyCharges    7043 non-null   float64 \n",
      " 18  TotalCharges      7043 non-null   object  \n",
      " 19  Churn             7043 non-null   category\n",
      "dtypes: category(17), float64(2), object(1)\n",
      "memory usage: 338.8+ KB\n"
     ]
    }
   ],
   "source": [
    "#EX-35 :Convert Categorical column to category type and numerical column to float type\n",
    "url = 'https://ml-repository-krakers.s3-eu-west-1.amazonaws.com/kaggle+/churn_modelling/Telco-Customer-Churn.csv'\n",
    "df = pd.read_csv(url, index_col=0)\n",
    "categorical = ['gender', 'SeniorCitizen', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines', \n",
    "               'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport',\n",
    "               'StreamingTV', 'Contract', 'StreamingMovies', 'PaperlessBilling', 'PaymentMethod', 'Churn'] \n",
    "\n",
    "numerical = ['tenure', 'MonthlyCharges']\n",
    "\n",
    "for col in categorical:\n",
    "    df[col] = pd.Categorical(df[col]) \n",
    " \n",
    "for col in numerical:\n",
    "    df[col] = df[col].astype(float)\n",
    " \n",
    "df.info()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       gender  SeniorCitizen Partner Dependents PhoneService MultipleLines  \\\n",
      "count    7043           7043    7043       7043         7043          7043   \n",
      "unique      2              2       2          2            2             3   \n",
      "top      Male              0      No         No          Yes            No   \n",
      "freq     3555           5901    3641       4933         6361          3390   \n",
      "\n",
      "       InternetService OnlineSecurity OnlineBackup DeviceProtection  \\\n",
      "count             7043           7043         7043             7043   \n",
      "unique               3              3            3                3   \n",
      "top        Fiber optic             No           No               No   \n",
      "freq              3096           3498         3088             3095   \n",
      "\n",
      "       TechSupport StreamingTV StreamingMovies        Contract  \\\n",
      "count         7043        7043            7043            7043   \n",
      "unique           3           3               3               3   \n",
      "top             No          No              No  Month-to-month   \n",
      "freq          3473        2810            2785            3875   \n",
      "\n",
      "       PaperlessBilling     PaymentMethod Churn  \n",
      "count              7043              7043  7043  \n",
      "unique                2                 4     2  \n",
      "top                 Yes  Electronic check    No  \n",
      "freq               4171              2365  5174  \n"
     ]
    }
   ],
   "source": [
    "#EX-36: Print the basic statistics of categorical variable by using appropriate argument.\n",
    "\n",
    "url = 'https://ml-repository-krakers.s3-eu-west-1.amazonaws.com/kaggle+/churn_modelling/Telco-Customer-Churn.csv'\n",
    "df = pd.read_csv(url, index_col=0)\n",
    "TotalChargesMedian = df['TotalCharges'][df['TotalCharges'] != ' '].median()\n",
    "df.loc[df['TotalCharges'] == ' ', 'TotalCharges'] = TotalChargesMedian\n",
    "df['TotalCharges'] = df['TotalCharges'].astype('float')\n",
    " \n",
    "categorical = ['gender', 'SeniorCitizen', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines', \n",
    "               'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport',\n",
    "               'StreamingTV', 'Contract', 'StreamingMovies', 'PaperlessBilling', 'PaymentMethod', 'Churn'] \n",
    " \n",
    "numerical = ['tenure', 'MonthlyCharges']\n",
    " \n",
    "for col in categorical:\n",
    "    df[col] = pd.Categorical(df[col]) \n",
    " \n",
    "for col in numerical:\n",
    "    df[col] = df[col].astype(float)\n",
    " \n",
    "print(df.describe(include=['category']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No     5174\n",
      "Yes    1869\n",
      "Name: Churn, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#EX-37: Find the distribution of the churn variable\n",
    "url = 'https://ml-repository-krakers.s3-eu-west-1.amazonaws.com/kaggle+/churn_modelling/Telco-Customer-Churn.csv'\n",
    "df = pd.read_csv(url, index_col=0)\n",
    "print(df['Churn'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Churn  PaymentMethod            \n",
      "No     Bank transfer (automatic)    65.049417\n",
      "       Credit card (automatic)      64.562209\n",
      "       Electronic check             74.232032\n",
      "       Mailed check                 41.403911\n",
      "Yes    Bank transfer (automatic)    77.875581\n",
      "       Credit card (automatic)      77.356034\n",
      "       Electronic check             78.700980\n",
      "       Mailed check                 54.557143\n",
      "Name: MonthlyCharges, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#EX-38: Group this by 'Churn' and 'PaymentMethod' column and calculate the average value of 'MonthlyCharges' column.\n",
    "url = 'https://ml-repository-krakers.s3-eu-west-1.amazonaws.com/kaggle+/churn_modelling/Telco-Customer-Churn.csv'\n",
    "df = pd.read_csv(url, index_col=0)\n",
    "print(df.groupby(['Churn', 'PaymentMethod'])['MonthlyCharges'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            gender  SeniorCitizen Partner Dependents  tenure PhoneService  \\\n",
      "customerID                                                                  \n",
      "7590-VHVEG  Female              0     Yes         No       1           No   \n",
      "5575-GNVDE    Male              0      No         No      34          Yes   \n",
      "3668-QPYBK    Male              0      No         No       2          Yes   \n",
      "7795-CFOCW    Male              0      No         No      45           No   \n",
      "\n",
      "               MultipleLines InternetService OnlineSecurity OnlineBackup  \\\n",
      "customerID                                                                 \n",
      "7590-VHVEG  No phone service             DSL             No          Yes   \n",
      "5575-GNVDE                No             DSL            Yes           No   \n",
      "3668-QPYBK                No             DSL            Yes          Yes   \n",
      "7795-CFOCW  No phone service             DSL            Yes           No   \n",
      "\n",
      "           DeviceProtection TechSupport StreamingTV StreamingMovies  \\\n",
      "customerID                                                            \n",
      "7590-VHVEG               No          No          No              No   \n",
      "5575-GNVDE              Yes          No          No              No   \n",
      "3668-QPYBK               No          No          No              No   \n",
      "7795-CFOCW              Yes         Yes          No              No   \n",
      "\n",
      "                  Contract PaperlessBilling              PaymentMethod  \\\n",
      "customerID                                                               \n",
      "7590-VHVEG  Month-to-month              Yes           Electronic check   \n",
      "5575-GNVDE        One year               No               Mailed check   \n",
      "3668-QPYBK  Month-to-month              Yes               Mailed check   \n",
      "7795-CFOCW        One year               No  Bank transfer (automatic)   \n",
      "\n",
      "            MonthlyCharges TotalCharges  Churn  \n",
      "customerID                                      \n",
      "7590-VHVEG           29.85        29.85      0  \n",
      "5575-GNVDE           56.95       1889.5      0  \n",
      "3668-QPYBK           53.85       108.15      1  \n",
      "7795-CFOCW           42.30      1840.75      0  \n"
     ]
    }
   ],
   "source": [
    "#EX-39: Map the Churn column as 'Yes -> 1' and 'No -> 0'\n",
    "url = 'https://ml-repository-krakers.s3-eu-west-1.amazonaws.com/kaggle+/churn_modelling/Telco-Customer-Churn.csv'\n",
    "df = pd.read_csv(url, index_col=0)\n",
    "df['Churn'] = df['Churn'].map({'Yes': 1, 'No': 0})\n",
    "print(df.head(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                SeniorCitizen    tenure  MonthlyCharges\n",
      "SeniorCitizen        1.000000  0.016567        0.220173\n",
      "tenure               0.016567  1.000000        0.247900\n",
      "MonthlyCharges       0.220173  0.247900        1.000000\n"
     ]
    }
   ],
   "source": [
    "#EX-40: Calculate the correlation matrix of Dataframe.\n",
    "url = 'https://ml-repository-krakers.s3-eu-west-1.amazonaws.com/kaggle+/churn_modelling/Telco-Customer-Churn.csv'\n",
    "df = pd.read_csv(url, index_col=0)\n",
    "print(df.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EX-41: Take Sample of 10 rows and save it to sample_10.csv\n",
    "np.random.seed(42)\n",
    "\n",
    "url = 'https://ml-repository-krakers.s3-eu-west-1.amazonaws.com/kaggle+/churn_modelling/Telco-Customer-Churn.csv'\n",
    "df = pd.read_csv(url, index_col=0)\n",
    "df.sample(10).to_csv('sample_10.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       col1      col2\n",
      "0  0.169759 -0.414616\n",
      "1  0.095641  0.944006\n",
      "2  0.419136 -0.462353\n",
      "3  0.113300  0.411448\n",
      "4  0.171913 -1.371367\n"
     ]
    }
   ],
   "source": [
    "#EX-42: s1 = pd.Series(np.random.rand(20)) s2 = pd.Series(np.random.randn(20)) Combine this 2 series into 1 dataframe and assign it to df\n",
    "#Set the column names 'col1' & 'col2'\n",
    "s1 = pd.Series(np.random.rand(20))\n",
    "s2 = pd.Series(np.random.randn(20))\n",
    "\n",
    "df = pd.concat([s1, s2], axis=1)\n",
    "df.columns = ['col1', 'col2']\n",
    "print(df.head())\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        col1      col2\n",
      "1   0.950714  0.314247\n",
      "6   0.058084  0.067528\n",
      "9   0.708073  0.110923\n",
      "11  0.969910  0.375698\n",
      "18  0.431945  0.822545\n"
     ]
    }
   ],
   "source": [
    "#EX-43: Extract rows for col2 which contains 0.0 and 1.0\n",
    " \n",
    "np.random.seed(42)\n",
    "s1 = pd.Series(np.random.rand(20))\n",
    "s2 = pd.Series(np.random.randn(20))\n",
    "\n",
    "df = pd.concat([s1, s2], axis=1)\n",
    "df.columns = ['col1', 'col2']\n",
    "print(df[df['col2'].between(0.0, 1.0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        col1      col2  col3\n",
      "0   0.374540 -1.012831    -1\n",
      "1   0.950714  0.314247     1\n",
      "2   0.731994 -0.908024    -1\n",
      "3   0.598658 -1.412304    -1\n",
      "4   0.156019  1.465649     1\n",
      "5   0.155995 -0.225776    -1\n",
      "6   0.058084  0.067528     1\n",
      "7   0.866176 -1.424748    -1\n",
      "8   0.601115 -0.544383    -1\n",
      "9   0.708073  0.110923     1\n",
      "10  0.020584 -1.150994    -1\n",
      "11  0.969910  0.375698     1\n",
      "12  0.832443 -0.600639    -1\n",
      "13  0.212339 -0.291694    -1\n",
      "14  0.181825 -0.601707    -1\n",
      "15  0.183405  1.852278     1\n",
      "16  0.304242 -0.013497    -1\n",
      "17  0.524756 -1.057711    -1\n",
      "18  0.431945  0.822545     1\n",
      "19  0.291229 -1.220844    -1\n"
     ]
    }
   ],
   "source": [
    "#EX-44: Assign a new column name 'col3' which will store 1 when the value of col2 is non-negative and -1 opposite\n",
    "np.random.seed(42)\n",
    "s1 = pd.Series(np.random.rand(20))\n",
    "s2 = pd.Series(np.random.randn(20))\n",
    "\n",
    "df = pd.concat([s1, s2], axis=1)\n",
    "df.columns = ['col1', 'col2']\n",
    "df['col3'] = df['col2'].map(lambda x: 1 if x >= 0 else -1)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        col1      col2  col3      col4\n",
      "0   0.374540 -1.012831    -1 -1.000000\n",
      "1   0.950714  0.314247     1  0.314247\n",
      "2   0.731994 -0.908024    -1 -0.908024\n",
      "3   0.598658 -1.412304    -1 -1.000000\n",
      "4   0.156019  1.465649     1  1.000000\n",
      "5   0.155995 -0.225776    -1 -0.225776\n",
      "6   0.058084  0.067528     1  0.067528\n",
      "7   0.866176 -1.424748    -1 -1.000000\n",
      "8   0.601115 -0.544383    -1 -0.544383\n",
      "9   0.708073  0.110923     1  0.110923\n",
      "10  0.020584 -1.150994    -1 -1.000000\n",
      "11  0.969910  0.375698     1  0.375698\n",
      "12  0.832443 -0.600639    -1 -0.600639\n",
      "13  0.212339 -0.291694    -1 -0.291694\n",
      "14  0.181825 -0.601707    -1 -0.601707\n",
      "15  0.183405  1.852278     1  1.000000\n",
      "16  0.304242 -0.013497    -1 -0.013497\n",
      "17  0.524756 -1.057711    -1 -1.000000\n",
      "18  0.431945  0.822545     1  0.822545\n",
      "19  0.291229 -1.220844    -1 -1.000000\n"
     ]
    }
   ],
   "source": [
    "#EX-45: Assign a new column 'col4' which will truncate the values from col2 to the range [-1.0,1.0]\n",
    "np.random.seed(42)\n",
    "s1 = pd.Series(np.random.rand(20))\n",
    "s2 = pd.Series(np.random.randn(20))\n",
    "\n",
    "df = pd.concat([s1, s2], axis=1)\n",
    "df.columns = ['col1', 'col2']\n",
    "df['col3'] = df['col2'].map(lambda x: 1 if x >= 0 else -1)\n",
    "df['col4'] = df['col2'].clip(-1.0, 1.0)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15    1.852278\n",
      "4     1.465649\n",
      "18    0.822545\n",
      "11    0.375698\n",
      "1     0.314247\n",
      "Name: col2, dtype: float64\n",
      "\n",
      "7    -1.424748\n",
      "3    -1.412304\n",
      "19   -1.220844\n",
      "10   -1.150994\n",
      "17   -1.057711\n",
      "Name: col2, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#EX-46: Print the 5 largest value for col2, print blank and print the 5 lowest value for col2\n",
    "np.random.seed(42)\n",
    "s1 = pd.Series(np.random.rand(20))\n",
    "s2 = pd.Series(np.random.randn(20))\n",
    "\n",
    "df = pd.concat([s1, s2], axis=1)\n",
    "df.columns = ['col1', 'col2']\n",
    "print(df['col2'].nlargest(5))\n",
    "print()\n",
    "print(df['col2'].nsmallest(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        col1      col2\n",
      "0   0.374540 -1.012831\n",
      "1   1.325254 -0.698584\n",
      "2   2.057248 -1.606608\n",
      "3   2.655907 -3.018912\n",
      "4   2.811925 -1.553263\n",
      "5   2.967920 -1.779039\n",
      "6   3.026004 -1.711511\n",
      "7   3.892180 -3.136259\n",
      "8   4.493295 -3.680642\n",
      "9   5.201367 -3.569719\n",
      "10  5.221952 -4.720713\n",
      "11  6.191862 -4.345015\n",
      "12  7.024304 -4.945653\n",
      "13  7.236643 -5.237347\n",
      "14  7.418468 -5.839054\n",
      "15  7.601873 -3.986776\n",
      "16  7.906115 -4.000273\n",
      "17  8.430872 -5.057984\n",
      "18  8.862817 -4.235439\n",
      "19  9.154046 -5.456283\n"
     ]
    }
   ],
   "source": [
    "#EX-47: Calculate cumulative sum for each column and print result\n",
    "np.random.seed(42)\n",
    "s1 = pd.Series(np.random.rand(20))\n",
    "s2 = pd.Series(np.random.randn(20))\n",
    "\n",
    "df = pd.concat([s1, s2], axis=1)\n",
    "df.columns = ['col1', 'col2']\n",
    "print(df.cumsum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.4180382371592297\n"
     ]
    }
   ],
   "source": [
    "#EX-48(A): Calculate median for the col2 \n",
    "np.random.seed(42)\n",
    "s1 = pd.Series(np.random.rand(20))\n",
    "s2 = pd.Series(np.random.randn(20))\n",
    "\n",
    "df = pd.concat([s1, s2], axis=1)\n",
    "df.columns = ['col1', 'col2']\n",
    "print(df['col2'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.4180382371592297\n"
     ]
    }
   ],
   "source": [
    "#EX-48(B): Calculate median for the col2 \n",
    "np.random.seed(42)\n",
    "s1 = pd.Series(np.random.rand(20))\n",
    "s2 = pd.Series(np.random.randn(20))\n",
    "\n",
    "df = pd.concat([s1, s2], axis=1)\n",
    "df.columns = ['col1', 'col2']\n",
    "print(df['col2'].quantile())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        col1      col2\n",
      "1   0.950714  0.314247\n",
      "4   0.156019  1.465649\n",
      "6   0.058084  0.067528\n",
      "9   0.708073  0.110923\n",
      "11  0.969910  0.375698\n",
      "15  0.183405  1.852278\n",
      "18  0.431945  0.822545\n"
     ]
    }
   ],
   "source": [
    "#EX-49: Extract rows for which col2 takes value greater than 0.0\n",
    "np.random.seed(42)\n",
    "s1 = pd.Series(np.random.rand(20))\n",
    "s2 = pd.Series(np.random.randn(20))\n",
    " \n",
    "df = pd.concat([s1, s2], axis=1)\n",
    "df.columns = ['col1', 'col2']\n",
    "print(df.query(\"col2 > 0\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'col1': {0: 0.3745401188473625, 1: 0.9507143064099162, 2: 0.7319939418114051, 3: 0.5986584841970366, 4: 0.15601864044243652}, 'col2': {0: -1.0128311203344238, 1: 0.3142473325952739, 2: -0.9080240755212109, 3: -1.4123037013352915, 4: 1.465648768921554}}\n"
     ]
    }
   ],
   "source": [
    "#EX-50(A): Extract the first 5 rows of df and convert it into dictionary\n",
    "np.random.seed(42)\n",
    "s1 = pd.Series(np.random.rand(20))\n",
    "s2 = pd.Series(np.random.randn(20))\n",
    "\n",
    "df = pd.concat([s1, s2], axis=1)\n",
    "df.columns = ['col1', 'col2']\n",
    "print(df.head().to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'col1': {0: 0.3745401188473625, 1: 0.9507143064099162, 2: 0.7319939418114051, 3: 0.5986584841970366, 4: 0.15601864044243652}, 'col2': {0: -1.0128311203344238, 1: 0.3142473325952739, 2: -0.9080240755212109, 3: -1.4123037013352915, 4: 1.465648768921554}}\n"
     ]
    }
   ],
   "source": [
    "#EX-50(A): Extract the first 5 rows of df and convert it into dictionary\n",
    "np.random.seed(42)\n",
    "s1 = pd.Series(np.random.rand(20))\n",
    "s2 = pd.Series(np.random.randn(20))\n",
    "\n",
    "df = pd.concat([s1, s2], axis=1)\n",
    "df.columns = ['col1', 'col2']\n",
    "print(df[:5].to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<table border=\"1\" class=\"dataframe\">\n",
      "  <thead>\n",
      "    <tr style=\"text-align: right;\">\n",
      "      <th></th>\n",
      "      <th>col1</th>\n",
      "      <th>col2</th>\n",
      "    </tr>\n",
      "  </thead>\n",
      "  <tbody>\n",
      "    <tr>\n",
      "      <th>0</th>\n",
      "      <td>0.374540</td>\n",
      "      <td>-1.012831</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <th>1</th>\n",
      "      <td>0.950714</td>\n",
      "      <td>0.314247</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <th>2</th>\n",
      "      <td>0.731994</td>\n",
      "      <td>-0.908024</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <th>3</th>\n",
      "      <td>0.598658</td>\n",
      "      <td>-1.412304</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <th>4</th>\n",
      "      <td>0.156019</td>\n",
      "      <td>1.465649</td>\n",
      "    </tr>\n",
      "  </tbody>\n",
      "</table>\n"
     ]
    }
   ],
   "source": [
    "#EX-51(A): Extract first 5 rows and convert it to HTML, assign it to df_html variable\n",
    "np.random.seed(42)\n",
    "s1 = pd.Series(np.random.rand(20))\n",
    "s2 = pd.Series(np.random.randn(20))\n",
    " \n",
    "df = pd.concat([s1, s2], axis=1)\n",
    "df.columns = ['col1', 'col2']\n",
    "print(df.head().to_html())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<table border=\"1\" class=\"dataframe\">\n",
      "  <thead>\n",
      "    <tr style=\"text-align: right;\">\n",
      "      <th></th>\n",
      "      <th>col1</th>\n",
      "      <th>col2</th>\n",
      "    </tr>\n",
      "  </thead>\n",
      "  <tbody>\n",
      "    <tr>\n",
      "      <th>0</th>\n",
      "      <td>0.374540</td>\n",
      "      <td>-1.012831</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <th>1</th>\n",
      "      <td>0.950714</td>\n",
      "      <td>0.314247</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <th>2</th>\n",
      "      <td>0.731994</td>\n",
      "      <td>-0.908024</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <th>3</th>\n",
      "      <td>0.598658</td>\n",
      "      <td>-1.412304</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <th>4</th>\n",
      "      <td>0.156019</td>\n",
      "      <td>1.465649</td>\n",
      "    </tr>\n",
      "  </tbody>\n",
      "</table>\n"
     ]
    }
   ],
   "source": [
    "#EX-51(A): Extract first 5 rows and convert it to HTML, assign it to df_html variable\n",
    "np.random.seed(42)\n",
    "s1 = pd.Series(np.random.rand(20))\n",
    "s2 = pd.Series(np.random.randn(20))\n",
    " \n",
    "df = pd.concat([s1, s2], axis=1)\n",
    "df.columns = ['col1', 'col2']\n",
    "print(df[:5].to_html())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          A         B         C         D\n",
      "8  0.065052  0.948886  0.965632  0.808397\n"
     ]
    }
   ],
   "source": [
    "#EX-52: Extract rows of dataframe for which C column is greater than 0.8\n",
    "\n",
    "np.random.seed(42)\n",
    "df = pd.DataFrame(np.random.rand(10, 4), columns=list('ABCD'))\n",
    "print(df.loc[df['C'] > 0.8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          A         B         C         D\n",
      "0  0.374540  0.950714  0.731994  0.598658\n",
      "4  0.304242  0.524756  0.431945  0.291229\n",
      "7  0.592415  0.046450  0.607545  0.170524\n",
      "9  0.304614  0.097672  0.684233  0.440152\n"
     ]
    }
   ],
   "source": [
    "#EX-53: Extract rows of dataframe for which C column is greater than 0.3 and D column is less than 0.7\n",
    "np.random.seed(42)\n",
    "df = pd.DataFrame(np.random.rand(10, 4), columns=list('ABCD'))\n",
    "print( df.loc[ (df['C'] > 0.3) & (df['D'] < 0.7)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A    0.374540\n",
      "B    0.950714\n",
      "C    0.731994\n",
      "D    0.598658\n",
      "Name: 0, dtype: float64\n",
      "A    0.156019\n",
      "B    0.155995\n",
      "C    0.058084\n",
      "D    0.866176\n",
      "Name: 1, dtype: float64\n",
      "A    0.601115\n",
      "B    0.708073\n",
      "C    0.020584\n",
      "D    0.969910\n",
      "Name: 2, dtype: float64\n",
      "A    0.832443\n",
      "B    0.212339\n",
      "C    0.181825\n",
      "D    0.183405\n",
      "Name: 3, dtype: float64\n",
      "A    0.304242\n",
      "B    0.524756\n",
      "C    0.431945\n",
      "D    0.291229\n",
      "Name: 4, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#EX-54: Iterate first 5 row of this object\n",
    "np.random.seed(42)\n",
    "df = pd.DataFrame(np.random.rand(10, 4), columns=list('ABCD'))\n",
    "for index, row in df.head().iterrows():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          A         B         C         D\n",
      "0  0.374540  0.950714  0.731994  0.598658\n",
      "1  0.156019  0.155995  0.058084  0.866176\n",
      "2  0.601115  0.708073  0.020584  0.969910\n",
      "3  0.832443       NaN  0.181825  0.183405\n",
      "4  0.304242  0.524756  0.431945  0.291229\n",
      "5  0.611853  0.139494  0.292145  0.366362\n",
      "6  0.456070  0.785176  0.199674  0.514234\n",
      "7  0.592415  0.046450  0.607545  0.170524\n",
      "8  0.065052  0.948886  0.965632       NaN\n",
      "9  0.304614  0.097672  0.684233  0.440152\n"
     ]
    }
   ],
   "source": [
    "#EX-55: set the value in row with index 3 for column B as np.nan and also set the value in a row at index 8 for column D\n",
    "np.random.seed(42)\n",
    "df = pd.DataFrame(np.random.rand(10, 4), columns=list('ABCD'))\n",
    "df.iloc[3, 1] = np.nan\n",
    "df.loc[8, 'D'] = np.nan\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          A         B         C         D\n",
      "0  0.374540  0.950714  0.731994  0.598658\n",
      "1  0.156019  0.155995  0.058084  0.866176\n",
      "2  0.601115  0.708073  0.020584  0.969910\n",
      "4  0.304242  0.524756  0.431945  0.291229\n",
      "5  0.611853  0.139494  0.292145  0.366362\n",
      "6  0.456070  0.785176  0.199674  0.514234\n",
      "7  0.592415  0.046450  0.607545  0.170524\n",
      "9  0.304614  0.097672  0.684233  0.440152\n"
     ]
    }
   ],
   "source": [
    "#EX-56:Remove all rows which contain missing values and assign it to df1 variable\n",
    "\n",
    "np.random.seed(42)\n",
    "df = pd.DataFrame(np.random.rand(10, 4), columns=list('ABCD'))\n",
    "df.iloc[3, 1] = np.nan\n",
    "df.loc[8, 'D'] = np.nan\n",
    "df1 = df.dropna()\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          A         B         C         D\n",
      "0  0.374540  0.950714  0.731994  0.598658\n",
      "1  0.156019  0.155995  0.058084  0.866176\n",
      "2  0.601115  0.708073  0.020584  0.969910\n",
      "3  0.304242  0.524756  0.431945  0.291229\n",
      "4  0.611853  0.139494  0.292145  0.366362\n",
      "5  0.456070  0.785176  0.199674  0.514234\n",
      "6  0.592415  0.046450  0.607545  0.170524\n",
      "7  0.304614  0.097672  0.684233  0.440152\n"
     ]
    }
   ],
   "source": [
    "#EX-57: Reset the index of above dataframe\n",
    "np.random.seed(42)\n",
    "df = pd.DataFrame(np.random.rand(10, 4), columns=list('ABCD'))\n",
    "df.iloc[3, 1] = np.nan\n",
    "df.loc[8, 'D'] = np.nan\n",
    "df1 = df.dropna()\n",
    "print(df1.reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A    0\n",
      "B    1\n",
      "C    0\n",
      "D    1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#EX-58: Calculate the number of missing values for each column\n",
    "np.random.seed(42)\n",
    "df = pd.DataFrame(np.random.rand(10, 4), columns=list('ABCD'))\n",
    "df.iloc[3, 1] = np.nan\n",
    "df.loc[8, 'D'] = np.nan\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          A         B         C         D\n",
      "0  0.374540  0.950714  0.731994  0.598658\n",
      "1  0.156019  0.155995  0.058084  0.866176\n",
      "2  0.601115  0.708073  0.020584  0.969910\n",
      "3  0.832443  0.000000  0.181825  0.183405\n",
      "4  0.304242  0.524756  0.431945  0.291229\n",
      "5  0.611853  0.139494  0.292145  0.366362\n",
      "6  0.456070  0.785176  0.199674  0.514234\n",
      "7  0.592415  0.046450  0.607545  0.170524\n",
      "8  0.065052  0.948886  0.965632  0.000000\n",
      "9  0.304614  0.097672  0.684233  0.440152\n"
     ]
    }
   ],
   "source": [
    "#EX-59: fill the missing value with 0 and assign it to variable df\n",
    "np.random.seed(42)\n",
    "df = pd.DataFrame(np.random.rand(10, 4), columns=list('ABCD'))\n",
    "df.iloc[3, 1] = np.nan\n",
    "df.loc[8, 'D'] = np.nan\n",
    "df = df.fillna(0)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          D         A         B         C\n",
      "0  0.598658  0.374540  0.950714  0.731994\n",
      "1  0.866176  0.156019  0.155995  0.058084\n",
      "2  0.969910  0.601115  0.708073  0.020584\n",
      "3  0.183405  0.832443  0.212339  0.181825\n",
      "4  0.291229  0.304242  0.524756  0.431945\n",
      "5  0.366362  0.611853  0.139494  0.292145\n",
      "6  0.514234  0.456070  0.785176  0.199674\n",
      "7  0.170524  0.592415  0.046450  0.607545\n",
      "8  0.808397  0.065052  0.948886  0.965632\n",
      "9  0.440152  0.304614  0.097672  0.684233\n"
     ]
    }
   ],
   "source": [
    "#EX-60: Replace the order of the column as D,A,B,C\n",
    "\n",
    "np.random.seed(42)\n",
    "df = pd.DataFrame(np.random.rand(10, 4), columns=list('ABCD'))\n",
    "df = df[['D', 'A', 'B', 'C']]\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          A         B         C\n",
      "0  0.374540  0.950714  0.731994\n",
      "1  0.156019  0.155995  0.058084\n",
      "2  0.601115  0.708073  0.020584\n",
      "3  0.832443  0.212339  0.181825\n",
      "4  0.304242  0.524756  0.431945\n",
      "5  0.611853  0.139494  0.292145\n",
      "6  0.456070  0.785176  0.199674\n",
      "7  0.592415  0.046450  0.607545\n",
      "8  0.065052  0.948886  0.965632\n",
      "9  0.304614  0.097672  0.684233\n"
     ]
    }
   ],
   "source": [
    "#EX-61: Remove the D column from the Dataframe\n",
    "np.random.seed(42)\n",
    "df = pd.DataFrame(np.random.rand(10, 4), columns=list('ABCD'))\n",
    "df = df.drop('D', axis=1)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               Name    Location  Year  Kilometers_Driven  \\\n",
      "0            Maruti Wagon R LXI CNG      Mumbai  2010              72000   \n",
      "1  Hyundai Creta 1.6 CRDi SX Option        Pune  2015              41000   \n",
      "2                      Honda Jazz V     Chennai  2011              46000   \n",
      "3                 Maruti Ertiga VDI     Chennai  2012              87000   \n",
      "4   Audi A4 New 2.0 TDI Multitronic  Coimbatore  2013              40670   \n",
      "\n",
      "  Fuel_Type Transmission Owner_Type     Mileage   Engine      Power  Seats  \\\n",
      "0       CNG       Manual      First  26.6 km/kg   998 CC  58.16 bhp    5.0   \n",
      "1    Diesel       Manual      First  19.67 kmpl  1582 CC  126.2 bhp    5.0   \n",
      "2    Petrol       Manual      First   18.2 kmpl  1199 CC   88.7 bhp    5.0   \n",
      "3    Diesel       Manual      First  20.77 kmpl  1248 CC  88.76 bhp    7.0   \n",
      "4    Diesel    Automatic     Second   15.2 kmpl  1968 CC  140.8 bhp    5.0   \n",
      "\n",
      "   New_Price  Price  \n",
      "0        NaN   1.75  \n",
      "1        NaN  12.50  \n",
      "2  8.61 Lakh   4.50  \n",
      "3        NaN   6.00  \n",
      "4        NaN  17.74  \n"
     ]
    }
   ],
   "source": [
    "#EX-62: Use pandas to load following CSV and set index to the first column\n",
    "url = 'https://storage.googleapis.com/esmartdata-courses-files/dash-course/data.csv'\n",
    "df = pd.read_csv(url, index_col=0)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Name', 'Location', 'Year', 'Kilometers_Driven', 'Fuel_Type', 'Transmission', 'Owner_Type', 'Mileage', 'Engine', 'Power', 'Seats', 'New_Price', 'Price']\n"
     ]
    }
   ],
   "source": [
    "#EX-63: Extract list with column names\n",
    "url = 'https://storage.googleapis.com/esmartdata-courses-files/dash-course/data.csv'\n",
    "df = pd.read_csv(url, index_col=0)\n",
    "print(list(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               Name    Location  Year  Kilometers_Driven  \\\n",
      "0            Maruti Wagon R LXI CNG      Mumbai  2010              72000   \n",
      "1  Hyundai Creta 1.6 CRDi SX Option        Pune  2015              41000   \n",
      "2                      Honda Jazz V     Chennai  2011              46000   \n",
      "3                 Maruti Ertiga VDI     Chennai  2012              87000   \n",
      "4   Audi A4 New 2.0 TDI Multitronic  Coimbatore  2013              40670   \n",
      "\n",
      "  Fuel_Type Transmission Owner_Type     Mileage   Engine      Power  Seats  \\\n",
      "0       CNG       Manual      First  26.6 km/kg   998 CC  58.16 bhp    5.0   \n",
      "1    Diesel       Manual      First  19.67 kmpl  1582 CC  126.2 bhp    5.0   \n",
      "2    Petrol       Manual      First   18.2 kmpl  1199 CC   88.7 bhp    5.0   \n",
      "3    Diesel       Manual      First  20.77 kmpl  1248 CC  88.76 bhp    7.0   \n",
      "4    Diesel    Automatic     Second   15.2 kmpl  1968 CC  140.8 bhp    5.0   \n",
      "\n",
      "   Price  \n",
      "0   1.75  \n",
      "1  12.50  \n",
      "2   4.50  \n",
      "3   6.00  \n",
      "4  17.74  \n"
     ]
    }
   ],
   "source": [
    "#EX-64: Remove column New_Price and print first 5 rows\n",
    "url = 'https://storage.googleapis.com/esmartdata-courses-files/dash-course/data.csv'\n",
    "df = pd.read_csv(url, index_col=0)\n",
    "df.drop('New_Price', axis=1, inplace=True)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name                  0\n",
      "Location              0\n",
      "Year                  0\n",
      "Kilometers_Driven     0\n",
      "Fuel_Type             0\n",
      "Transmission          0\n",
      "Owner_Type            0\n",
      "Mileage               2\n",
      "Engine               36\n",
      "Power                36\n",
      "Seats                42\n",
      "Price                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#EX-65: Find the number of missing values for each column without New_Price column\n",
    "url = 'https://storage.googleapis.com/esmartdata-courses-files/dash-course/data.csv'\n",
    "df = pd.read_csv(url, index_col=0)\n",
    "df.drop('New_Price', axis=1, inplace=True)\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 823 entries, 2 to 6014\n",
      "Data columns (total 13 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Name               823 non-null    object \n",
      " 1   Location           823 non-null    object \n",
      " 2   Year               823 non-null    int64  \n",
      " 3   Kilometers_Driven  823 non-null    int64  \n",
      " 4   Fuel_Type          823 non-null    object \n",
      " 5   Transmission       823 non-null    object \n",
      " 6   Owner_Type         823 non-null    object \n",
      " 7   Mileage            823 non-null    object \n",
      " 8   Engine             823 non-null    object \n",
      " 9   Power              823 non-null    object \n",
      " 10  Seats              823 non-null    float64\n",
      " 11  New_Price          823 non-null    object \n",
      " 12  Price              823 non-null    float64\n",
      "dtypes: float64(2), int64(2), object(9)\n",
      "memory usage: 90.0+ KB\n"
     ]
    }
   ],
   "source": [
    "#EX-66: Removes all the rows with missing values and \n",
    "url = 'https://storage.googleapis.com/esmartdata-courses-files/dash-course/data.csv'\n",
    "df = pd.read_csv(url, index_col=0)\n",
    "df.dropna(inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               name    location  year  kilometers_driven  \\\n",
      "0            Maruti Wagon R LXI CNG      Mumbai  2010              72000   \n",
      "1  Hyundai Creta 1.6 CRDi SX Option        Pune  2015              41000   \n",
      "2                      Honda Jazz V     Chennai  2011              46000   \n",
      "3                 Maruti Ertiga VDI     Chennai  2012              87000   \n",
      "4   Audi A4 New 2.0 TDI Multitronic  Coimbatore  2013              40670   \n",
      "\n",
      "  fuel_type transmission owner_type     mileage   engine      power  seats  \\\n",
      "0       CNG       Manual      First  26.6 km/kg   998 CC  58.16 bhp    5.0   \n",
      "1    Diesel       Manual      First  19.67 kmpl  1582 CC  126.2 bhp    5.0   \n",
      "2    Petrol       Manual      First   18.2 kmpl  1199 CC   88.7 bhp    5.0   \n",
      "3    Diesel       Manual      First  20.77 kmpl  1248 CC  88.76 bhp    7.0   \n",
      "4    Diesel    Automatic     Second   15.2 kmpl  1968 CC  140.8 bhp    5.0   \n",
      "\n",
      "   new_price  price  \n",
      "0        NaN   1.75  \n",
      "1        NaN  12.50  \n",
      "2  8.61 Lakh   4.50  \n",
      "3        NaN   6.00  \n",
      "4        NaN  17.74  \n"
     ]
    }
   ],
   "source": [
    "#EX-67:Replace all letters in column name with lowercase e.g Name ->name\n",
    "\n",
    "url = 'https://storage.googleapis.com/esmartdata-courses-files/dash-course/data.csv'\n",
    "df = pd.read_csv(url, index_col=0)\n",
    "df.columns = [col.lower() for col in df.columns]\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First             4929\n",
      "Second             968\n",
      "Third              113\n",
      "Fourth & Above       9\n",
      "Name: owner_type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#EX-68:Find the distribution of the owner_type column\n",
    "\n",
    "url = 'https://storage.googleapis.com/esmartdata-courses-files/dash-course/data.csv'\n",
    "df = pd.read_csv(url, index_col=0)\n",
    "df.columns = [col.lower() for col in df.columns]\n",
    "print(df['owner_type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 name  engine\n",
      "2                        Honda Jazz V    1199\n",
      "7   Toyota Innova Crysta 2.8 GX AT 8S    2755\n",
      "10                   Maruti Ciaz Zeta    1462\n",
      "15        Mitsubishi Pajero Sport 4X4    2477\n",
      "20                  BMW 3 Series 320d    1995\n"
     ]
    }
   ],
   "source": [
    "#EX-69: Remove last 3 characters from each element from engine column and convert this column into int type\n",
    "url = 'https://storage.googleapis.com/esmartdata-courses-files/dash-course/data.csv'\n",
    "df = pd.read_csv(url, index_col=0)\n",
    "df.columns = [col.lower() for col in df.columns]\n",
    "df.dropna(inplace=True)\n",
    "df['engine'] = df['engine'].map(lambda x: int(x[:-3]))\n",
    "print(df[['name', 'engine']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74 bhp      235\n",
      "98.6 bhp    131\n",
      "73.9 bhp    125\n",
      "140 bhp     123\n",
      "78.9 bhp    111\n",
      "Name: power, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#EX-70: Replace the null value of column null bhp with np.nan \n",
    "url = 'https://storage.googleapis.com/esmartdata-courses-files/dash-course/data.csv'\n",
    "df = pd.read_csv(url, index_col=0)\n",
    "df.columns = [col.lower() for col in df.columns]\n",
    "df['power'] = np.where(df['power'] == 'null bhp', np.nan, df['power'])\n",
    "print(df['power'].value_counts()[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year\n",
      "1998      4\n",
      "1999      2\n",
      "2000      4\n",
      "2001      8\n",
      "2002     15\n",
      "2003     17\n",
      "2004     31\n",
      "2005     57\n",
      "2006     78\n",
      "2007    125\n",
      "2008    174\n",
      "2009    198\n",
      "2010    342\n",
      "2011    466\n",
      "2012    580\n",
      "2013    649\n",
      "2014    797\n",
      "2015    744\n",
      "2016    741\n",
      "2017    587\n",
      "2018    298\n",
      "2019    102\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#EX-71: Group this dataframe by year and count the number of rows for each year\n",
    "url = 'https://storage.googleapis.com/esmartdata-courses-files/dash-course/data.csv'\n",
    "df = pd.read_csv(url, index_col=0)\n",
    "df.columns = [col.lower() for col in df.columns]\n",
    "print(df.groupby('year').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    1\n",
      "Name: transmission, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#EX-72: Check the distribution of transmission column and perform mapping : 'Manual' -> 0 and 'Automatic' -> 1\n",
    "\n",
    "url = 'https://storage.googleapis.com/esmartdata-courses-files/dash-course/data.csv'\n",
    "df = pd.read_csv(url, index_col=0)\n",
    "df.columns = [col.lower() for col in df.columns]\n",
    "df['transmission'] = df['transmission'].map({'Manual': 0, 'Automatic': 1})\n",
    "print(df['transmission'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EX-73: Save object to cars.csv file(do not save index)\n",
    "url = 'https://storage.googleapis.com/esmartdata-courses-files/dash-course/data.csv'\n",
    "df = pd.read_csv(url, index_col=0)\n",
    "df.columns = [col.lower() for col in df.columns]\n",
    "df.to_csv('cars.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 17414 entries, 2015-01-04 00:00:00 to 2017-01-03 23:00:00\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   cnt           17414 non-null  int64  \n",
      " 1   t1            17414 non-null  float64\n",
      " 2   t2            17414 non-null  float64\n",
      " 3   hum           17414 non-null  float64\n",
      " 4   wind_speed    17414 non-null  float64\n",
      " 5   weather_code  17414 non-null  float64\n",
      " 6   is_holiday    17414 non-null  float64\n",
      " 7   is_weekend    17414 non-null  float64\n",
      " 8   season        17414 non-null  float64\n",
      "dtypes: float64(8), int64(1)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "#EX-74:Load Below file and save it to df variable\n",
    "url = 'https://storage.googleapis.com/esmartdata-courses-files/ds-bootcamp/london_bike.csv'\n",
    "df = pd.read_csv(url, index_col=0)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     cnt   t1   t2    hum  wind_speed  weather_code  is_holiday  is_weekend  season\n",
      "timestamp                                                                                          \n",
      "2015-01-04 00:00:00  182  3.0  2.0   93.0         6.0           3.0         0.0         1.0     3.0\n",
      "2015-01-04 01:00:00  138  3.0  2.5   93.0         5.0           1.0         0.0         1.0     3.0\n",
      "2015-01-04 02:00:00  134  2.5  2.5   96.5         0.0           1.0         0.0         1.0     3.0\n",
      "2015-01-04 03:00:00   72  2.0  2.0  100.0         0.0           1.0         0.0         1.0     3.0\n",
      "2015-01-04 04:00:00   47  2.0  0.0   93.0         6.5           1.0         0.0         1.0     3.0\n",
      "                      cnt   t1   t2   hum  wind_speed  weather_code  is_holiday  is_weekend  season\n",
      "timestamp                                                                                          \n",
      "2017-01-03 19:00:00  1042  5.0  1.0  81.0        19.0           3.0         0.0         0.0     3.0\n",
      "2017-01-03 20:00:00   541  5.0  1.0  81.0        21.0           4.0         0.0         0.0     3.0\n",
      "2017-01-03 21:00:00   337  5.5  1.5  78.5        24.0           4.0         0.0         0.0     3.0\n",
      "2017-01-03 22:00:00   224  5.5  1.5  76.0        23.0           4.0         0.0         0.0     3.0\n",
      "2017-01-03 23:00:00   139  5.0  1.0  76.0        22.0           2.0         0.0         0.0     3.0\n"
     ]
    }
   ],
   "source": [
    "#EX-75: Print the first and last five rows of this dataframe\n",
    "pd.set_option('max_columns', 9)\n",
    "pd.set_option('display.width', 150)\n",
    "url = 'https://storage.googleapis.com/esmartdata-courses-files/ds-bootcamp/london_bike.csv'\n",
    "df = pd.read_csv(url, index_col=0)\n",
    "print(df.head())\n",
    "print(df.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17414 entries, 0 to 17413\n",
      "Data columns (total 10 columns):\n",
      " #   Column        Non-Null Count  Dtype         \n",
      "---  ------        --------------  -----         \n",
      " 0   timestamp     17414 non-null  datetime64[ns]\n",
      " 1   cnt           17414 non-null  int64         \n",
      " 2   t1            17414 non-null  float64       \n",
      " 3   t2            17414 non-null  float64       \n",
      " 4   hum           17414 non-null  float64       \n",
      " 5   wind_speed    17414 non-null  float64       \n",
      " 6   weather_code  17414 non-null  float64       \n",
      " 7   is_holiday    17414 non-null  float64       \n",
      " 8   is_weekend    17414 non-null  float64       \n",
      " 9   season        17414 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(8), int64(1)\n",
      "memory usage: 1.3 MB\n"
     ]
    }
   ],
   "source": [
    "#EX-76: change timestamp column to datetime type\n",
    "pd.set_option('max_columns', 9)\n",
    "pd.set_option('display.width', 150)\n",
    "url = 'https://storage.googleapis.com/esmartdata-courses-files/ds-bootcamp/london_bike.csv'\n",
    "df = pd.read_csv(url)\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            timestamp  cnt   t1   t2    hum  wind_speed  weather_code  is_holiday  is_weekend  season  hour\n",
      "0 2015-01-04 00:00:00  182  3.0  2.0   93.0         6.0           3.0         0.0         1.0     3.0     0\n",
      "1 2015-01-04 01:00:00  138  3.0  2.5   93.0         5.0           1.0         0.0         1.0     3.0     1\n",
      "2 2015-01-04 02:00:00  134  2.5  2.5   96.5         0.0           1.0         0.0         1.0     3.0     2\n",
      "3 2015-01-04 03:00:00   72  2.0  2.0  100.0         0.0           1.0         0.0         1.0     3.0     3\n",
      "4 2015-01-04 04:00:00   47  2.0  0.0   93.0         6.5           1.0         0.0         1.0     3.0     4\n"
     ]
    }
   ],
   "source": [
    "#EX-77: Extract time in hours from timestamp column and assign it to new column 'hour'\n",
    "pd.set_option('max_columns', 15)\n",
    "pd.set_option('display.width', 150)\n",
    "url = 'https://storage.googleapis.com/esmartdata-courses-files/ds-bootcamp/london_bike.csv'\n",
    "df = pd.read_csv(url)\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df['hour'] = df['timestamp'].dt.hour\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            timestamp  cnt   t1   t2    hum  wind_speed  weather_code  is_holiday  is_weekend  season  month\n",
      "0 2015-01-04 00:00:00  182  3.0  2.0   93.0         6.0           3.0         0.0         1.0     3.0      1\n",
      "1 2015-01-04 01:00:00  138  3.0  2.5   93.0         5.0           1.0         0.0         1.0     3.0      1\n",
      "2 2015-01-04 02:00:00  134  2.5  2.5   96.5         0.0           1.0         0.0         1.0     3.0      1\n",
      "3 2015-01-04 03:00:00   72  2.0  2.0  100.0         0.0           1.0         0.0         1.0     3.0      1\n",
      "4 2015-01-04 04:00:00   47  2.0  0.0   93.0         6.5           1.0         0.0         1.0     3.0      1\n"
     ]
    }
   ],
   "source": [
    "#EX-78: Extract month from timestamp column and assign it to new column 'month'\n",
    "pd.set_option('max_columns', 15)\n",
    "pd.set_option('display.width', 150)\n",
    "url = 'https://storage.googleapis.com/esmartdata-courses-files/ds-bootcamp/london_bike.csv'\n",
    "df = pd.read_csv(url)\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df['month'] = df['timestamp'].dt.month\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    month        hum\n",
      "0       1  77.543376\n",
      "1       2  74.905813\n",
      "2       3  71.903781\n",
      "3       4  67.532337\n",
      "4       5  66.367272\n",
      "5       6  68.945148\n",
      "6       7  64.383525\n",
      "7       8  67.289420\n",
      "8       9  71.753228\n",
      "9      10  77.639621\n",
      "10     11  78.732517\n",
      "11     12  81.032345\n"
     ]
    }
   ],
   "source": [
    "#EX-79: Group by month and calculate average value for the hum column. Assign the result to humidity_by_month\n",
    "\n",
    "pd.set_option('max_columns', 15)\n",
    "pd.set_option('display.width', 150)\n",
    "url = 'https://storage.googleapis.com/esmartdata-courses-files/ds-bootcamp/london_bike.csv'\n",
    "df = pd.read_csv(url)\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df['month'] = df['timestamp'].dt.month\n",
    "humidity_by_month = df.groupby('month')['hum'].mean().reset_index()\n",
    "print(humidity_by_month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    hour          cnt\n",
      "0      0   290.609116\n",
      "1      1   200.631215\n",
      "2      2   136.303745\n",
      "3      3    94.245492\n",
      "4      4    73.313454\n",
      "5      5   110.707351\n",
      "6      6   466.626722\n",
      "7      7  1468.745179\n",
      "8      8  2882.823204\n",
      "9      9  1653.019257\n",
      "10    10  1064.660690\n",
      "11    11  1151.218707\n",
      "12    12  1433.717421\n",
      "13    13  1505.739011\n",
      "14    14  1472.004121\n",
      "15    15  1564.621399\n",
      "16    16  1869.801370\n",
      "17    17  2829.585165\n",
      "18    18  2629.043956\n",
      "19    19  1651.510316\n",
      "20    20  1059.781293\n",
      "21    21   741.249311\n",
      "22    22   592.409655\n",
      "23    23   439.652355\n"
     ]
    }
   ],
   "source": [
    "#EX-80: Group by month and calculate average value for the cnt column. Assign the result to cnt_by_hour\n",
    "\n",
    "pd.set_option('max_columns', 15)\n",
    "pd.set_option('display.width', 150)\n",
    "url = 'https://storage.googleapis.com/esmartdata-courses-files/ds-bootcamp/london_bike.csv'\n",
    "df = pd.read_csv(url)\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df['hour'] = df['timestamp'].dt.hour\n",
    "cnt_by_hour = df.groupby('hour')['cnt'].mean().reset_index()\n",
    "print(cnt_by_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    is_weekend  hour          cnt\n",
      "0          0.0     0   215.366795\n",
      "1          0.0     1   128.001931\n",
      "2          0.0     2    81.007737\n",
      "3          0.0     3    53.250000\n",
      "4          0.0     4    52.248062\n",
      "5          0.0     5   116.052326\n",
      "6          0.0     6   604.655106\n",
      "7          0.0     7  1969.518304\n",
      "8          0.0     8  3863.922780\n",
      "9          0.0     9  1997.605769\n",
      "10         0.0    10  1003.832692\n",
      "11         0.0    11   968.384615\n",
      "12         0.0    12  1233.938462\n",
      "13         0.0    13  1276.556840\n",
      "14         0.0    14  1211.795761\n",
      "15         0.0    15  1330.265385\n",
      "16         0.0    16  1801.692898\n",
      "17         0.0    17  3232.104046\n",
      "18         0.0    18  3051.809249\n",
      "19         0.0    19  1825.682081\n",
      "20         0.0    20  1133.965318\n",
      "21         0.0    21   789.131274\n",
      "22         0.0    22   614.686654\n",
      "23         0.0    23   434.893617\n",
      "24         1.0     0   479.810680\n",
      "25         1.0     1   383.262136\n",
      "26         1.0     2   276.441176\n",
      "27         1.0     3   197.434146\n",
      "28         1.0     4   126.336585\n",
      "29         1.0     5    97.253659\n",
      "30         1.0     6   120.555556\n",
      "31         1.0     7   213.183575\n",
      "32         1.0     8   415.786408\n",
      "33         1.0     9   787.391304\n",
      "34         1.0    10  1218.956098\n",
      "35         1.0    11  1610.512077\n",
      "36         1.0    12  1930.775120\n",
      "37         1.0    13  2074.856459\n",
      "38         1.0    14  2118.167464\n",
      "39         1.0    15  2147.708134\n",
      "40         1.0    16  2039.583732\n",
      "41         1.0    17  1830.028708\n",
      "42         1.0    18  1579.210526\n",
      "43         1.0    19  1216.918269\n",
      "44         1.0    20   874.677885\n",
      "45         1.0    21   622.004808\n",
      "46         1.0    22   537.038462\n",
      "47         1.0    23   451.653659\n"
     ]
    }
   ],
   "source": [
    "#EX-81: Group by is_weekend, hour column and calculate average value for the cnt column. Assign the result to cnt_by_weekend_hour\n",
    "\n",
    "pd.set_option('max_columns', 15)\n",
    "pd.set_option('display.width', 150)\n",
    "url = 'https://storage.googleapis.com/esmartdata-courses-files/ds-bootcamp/london_bike.csv'\n",
    "df = pd.read_csv(url)\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df['hour'] = df['timestamp'].dt.hour\n",
    "cnt_by_weekend_hour = df.groupby(['is_weekend', 'hour'])['cnt'].mean().reset_index()\n",
    "print(cnt_by_weekend_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                timestamp  cnt   t1   t2    hum  wind_speed  weather_code  is_holiday  is_weekend  season  hour\n",
      "0     2015-01-04 00:00:00  182  3.0  2.0   93.0         6.0           3.0         0.0         1.0     3.0     0\n",
      "1     2015-01-04 01:00:00  138  3.0  2.5   93.0         5.0           1.0         0.0         1.0     3.0     1\n",
      "2     2015-01-04 02:00:00  134  2.5  2.5   96.5         0.0           1.0         0.0         1.0     3.0     2\n",
      "3     2015-01-04 03:00:00   72  2.0  2.0  100.0         0.0           1.0         0.0         1.0     3.0     3\n",
      "4     2015-01-04 04:00:00   47  2.0  0.0   93.0         6.5           1.0         0.0         1.0     3.0     4\n",
      "...                   ...  ...  ...  ...    ...         ...           ...         ...         ...     ...   ...\n",
      "17312 2016-12-30 18:00:00  674  4.0  2.0  100.0         9.0           4.0         0.0         0.0     3.0    18\n",
      "17319 2016-12-31 01:00:00  123  5.0  3.5  100.0         7.5           4.0         0.0         1.0     3.0     1\n",
      "17320 2016-12-31 02:00:00   85  6.0  4.0   93.0         8.0           4.0         0.0         1.0     3.0     2\n",
      "17370 2017-01-02 04:00:00   18  3.0  0.5   93.0         8.0           2.0         1.0         0.0     3.0     4\n",
      "17371 2017-01-02 05:00:00   35  3.0  2.5   93.0         5.0           2.0         1.0         0.0     3.0     5\n",
      "\n",
      "[692 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "#EX-82: Extract rows for which wind_speed column is less than 10.0 and the hum is greater than 90.0\n",
    "pd.set_option('max_columns', 15)\n",
    "pd.set_option('display.width', 150)\n",
    "url = 'https://storage.googleapis.com/esmartdata-courses-files/ds-bootcamp/london_bike.csv'\n",
    "df = pd.read_csv(url)\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df['hour'] = df['timestamp'].dt.hour\n",
    "print(df.query(\"wind_speed < 10.0 and hum > 90.0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                timestamp  cnt   t1   t2    hum  wind_speed  weather_code  is_holiday  is_weekend  season  hour\n",
      "0     2015-01-04 00:00:00  182  3.0  2.0   93.0         6.0           3.0         0.0         1.0     3.0     0\n",
      "1     2015-01-04 01:00:00  138  3.0  2.5   93.0         5.0           1.0         0.0         1.0     3.0     1\n",
      "2     2015-01-04 02:00:00  134  2.5  2.5   96.5         0.0           1.0         0.0         1.0     3.0     2\n",
      "3     2015-01-04 03:00:00   72  2.0  2.0  100.0         0.0           1.0         0.0         1.0     3.0     3\n",
      "4     2015-01-04 04:00:00   47  2.0  0.0   93.0         6.5           1.0         0.0         1.0     3.0     4\n",
      "...                   ...  ...  ...  ...    ...         ...           ...         ...         ...     ...   ...\n",
      "17361 2017-01-01 19:00:00  136  5.0  2.0   93.0        15.0           7.0         0.0         1.0     3.0    19\n",
      "17362 2017-01-01 20:00:00  116  5.0  2.0   93.0        14.0           7.0         0.0         1.0     3.0    20\n",
      "17363 2017-01-01 21:00:00  110  5.0  2.0   93.0        14.0          26.0         0.0         1.0     3.0    21\n",
      "17364 2017-01-01 22:00:00  119  5.0  2.0   93.0        12.0           3.0         0.0         1.0     3.0    22\n",
      "17365 2017-01-01 23:00:00   89  5.0  2.5   90.0        10.0           1.0         0.0         1.0     3.0    23\n",
      "\n",
      "[4970 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "#EX-83: Extract rows for which is_weekend column is 1.0. Copy result to df_weekend\n",
    "pd.set_option('max_columns', 15)\n",
    "pd.set_option('display.width', 150)\n",
    "url = 'https://storage.googleapis.com/esmartdata-courses-files/ds-bootcamp/london_bike.csv'\n",
    "df = pd.read_csv(url)\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df['hour'] = df['timestamp'].dt.hour\n",
    "df_weekend = df.query(\"is_weekend == 1.0\").copy()\n",
    "print(df_weekend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EX-84: Save the df_weekend to weeken.txt file\n",
    "pd.set_option('max_columns', 15)\n",
    "pd.set_option('display.width', 150)\n",
    "url = 'https://storage.googleapis.com/esmartdata-courses-files/ds-bootcamp/london_bike.csv'\n",
    "df = pd.read_csv(url)\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df['hour'] = df['timestamp'].dt.hour\n",
    "df_weekend = df.query(\"is_weekend == 1.0\").copy()\n",
    "df_weekend.to_csv('weekend.txt', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age     sex     bmi  children smoker     region      charges\n",
      "0   19  female  27.900         0    yes  southwest  16884.92400\n",
      "1   18    male  33.770         1     no  southeast   1725.55230\n",
      "2   28    male  33.000         3     no  southeast   4449.46200\n",
      "3   33    male  22.705         0     no  northwest  21984.47061\n",
      "4   32    male  28.880         0     no  northwest   3866.85520\n"
     ]
    }
   ],
   "source": [
    "#EX-85:Load below file and assign it to df variable (Print first 5 rows)\n",
    "url = 'https://storage.googleapis.com/esmartdata-courses-files/ml-course/insurance.csv'\n",
    "df= pd.read_csv(url)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     age   sex    bmi  children smoker     region    charges\n",
      "581   19  male  30.59         0     no  northwest  1639.5631\n"
     ]
    }
   ],
   "source": [
    "#EX-86:Check for duplicate rows and print rows\n",
    "url = 'https://storage.googleapis.com/esmartdata-courses-files/ml-course/insurance.csv'\n",
    "df = pd.read_csv(url)\n",
    "print(df[df.duplicated()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1337 entries, 0 to 1337\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       1337 non-null   int64  \n",
      " 1   sex       1337 non-null   object \n",
      " 2   bmi       1337 non-null   float64\n",
      " 3   children  1337 non-null   int64  \n",
      " 4   smoker    1337 non-null   object \n",
      " 5   region    1337 non-null   object \n",
      " 6   charges   1337 non-null   float64\n",
      "dtypes: float64(2), int64(2), object(3)\n",
      "memory usage: 83.6+ KB\n"
     ]
    }
   ],
   "source": [
    "#EX-87: Remove duplicates from the oject\n",
    "url = 'https://storage.googleapis.com/esmartdata-courses-files/ml-course/insurance.csv'\n",
    "df = pd.read_csv(url)\n",
    "df = df.drop_duplicates()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         sex smoker     region\n",
      "0     female    yes  southwest\n",
      "1       male     no  southeast\n",
      "2       male     no  southeast\n",
      "3       male     no  northwest\n",
      "4       male     no  northwest\n",
      "...      ...    ...        ...\n",
      "1333    male     no  northwest\n",
      "1334  female     no  northeast\n",
      "1335  female     no  southeast\n",
      "1336  female     no  southwest\n",
      "1337  female    yes  northwest\n",
      "\n",
      "[1338 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#EX-88: Print the columns with object type\n",
    "url = 'https://storage.googleapis.com/esmartdata-courses-files/ml-course/insurance.csv'\n",
    "df = pd.read_csv(url)\n",
    "print(df.select_dtypes(include=['object']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1338 entries, 0 to 1337\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype   \n",
      "---  ------    --------------  -----   \n",
      " 0   age       1338 non-null   int64   \n",
      " 1   sex       1338 non-null   category\n",
      " 2   bmi       1338 non-null   float64 \n",
      " 3   children  1338 non-null   int64   \n",
      " 4   smoker    1338 non-null   category\n",
      " 5   region    1338 non-null   category\n",
      " 6   charges   1338 non-null   float64 \n",
      "dtypes: category(3), float64(2), int64(2)\n",
      "memory usage: 46.2 KB\n"
     ]
    }
   ],
   "source": [
    "#EX-89:Convert the column sex, smoker, region to category type\n",
    "url = 'https://storage.googleapis.com/esmartdata-courses-files/ml-course/insurance.csv'\n",
    "df = pd.read_csv(url)\n",
    "cat_vars = ['sex', 'smoker', 'region']\n",
    " \n",
    "for col in cat_vars:\n",
    "    df[col] = df[col].astype('category')\n",
    " \n",
    "df.info() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bmi', 'charges']\n"
     ]
    }
   ],
   "source": [
    "#EX-90:Extract all names of numeric columns(float, int) from this object as list\n",
    "url = 'https://storage.googleapis.com/esmartdata-courses-files/ml-course/insurance.csv'\n",
    "df = pd.read_csv(url)\n",
    "num_vars = list(df.select_dtypes(include=['float', 'int']).columns)\n",
    "print(num_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      sex smoker     region\n",
      "0  female    yes  southwest\n",
      "1    male     no  southeast\n",
      "2    male     no  southeast\n",
      "3    male     no  northwest\n",
      "4    male     no  northwest\n",
      "      bmi      charges\n",
      "0  27.900  16884.92400\n",
      "1  33.770   1725.55230\n",
      "2  33.000   4449.46200\n",
      "3  22.705  21984.47061\n",
      "4  28.880   3866.85520\n"
     ]
    }
   ],
   "source": [
    "#EX-91:Assign to the variable df_cat with categorical column from the df. Assign to the variable df_num with numerical column from the df\n",
    "url = 'https://storage.googleapis.com/esmartdata-courses-files/ml-course/insurance.csv'\n",
    "df = pd.read_csv(url)\n",
    "for col in list(df.select_dtypes(include=['object']).columns):\n",
    "    df[col] = df[col].astype('category')\n",
    "df_cat = df.select_dtypes(include=['category']).copy()\n",
    "df_num = df.select_dtypes(include=['float', 'int']).copy()\n",
    "print(df_cat.head())\n",
    "print(df_num.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         sex smoker     region\n",
      "count   1338   1338       1338\n",
      "unique     2      2          4\n",
      "top     male     no  southeast\n",
      "freq     676   1064        364\n"
     ]
    }
   ],
   "source": [
    "#EX-92: Print basic statistics of below dataframe\n",
    "url = 'https://storage.googleapis.com/esmartdata-courses-files/ml-course/insurance.csv'\n",
    "df = pd.read_csv(url)\n",
    "for col in list(df.select_dtypes(include=['object']).columns):\n",
    "    df[col] = df[col].astype('category')\n",
    "df_cat = df.select_dtypes(include=['category']).copy()\n",
    "print(df_cat.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               bmi       charges\n",
      "count  1338.000000   1338.000000\n",
      "mean     30.663397  13270.422265\n",
      "std       6.098187  12110.011237\n",
      "min      15.960000   1121.873900\n",
      "25%      26.296250   4740.287150\n",
      "50%      30.400000   9382.033000\n",
      "75%      34.693750  16639.912515\n",
      "max      53.130000  63770.428010\n"
     ]
    }
   ],
   "source": [
    "#EX-93:Print basic statistics of below dataframe\n",
    "url = 'https://storage.googleapis.com/esmartdata-courses-files/ml-course/insurance.csv'\n",
    "df = pd.read_csv(url)\n",
    "for col in list(df.select_dtypes(include=['object']).columns):\n",
    "    df[col] = df[col].astype('category')\n",
    "df_num = df.select_dtypes(include=['float', 'int']).copy()\n",
    "print(df_num.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  mean           std\n",
      "age          39.207025     14.049960\n",
      "bmi          30.663397      6.098187\n",
      "children      1.094918      1.205493\n",
      "charges   13270.422265  12110.011237\n"
     ]
    }
   ],
   "source": [
    "#EX-94:Calculate the basic statistics only for numeric variable, transpose the result and extract columns (mean, std)\n",
    "\n",
    "url = 'https://storage.googleapis.com/esmartdata-courses-files/ml-course/insurance.csv'\n",
    "df = pd.read_csv(url)\n",
    "print(df.describe().T[['mean', 'std']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age         0\n",
      "sex         0\n",
      "bmi         0\n",
      "children    0\n",
      "smoker      0\n",
      "region      0\n",
      "charges     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#EX-95:Check missing value from dataframes\n",
    "url = 'https://storage.googleapis.com/esmartdata-courses-files/ml-course/insurance.csv'\n",
    "df = pd.read_csv(url)\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age     bmi  children      charges  sex_male  smoker_yes  region_northwest  region_southeast  region_southwest\n",
      "0   19  27.900         0  16884.92400         0           1                 0                 0                 1\n",
      "1   18  33.770         1   1725.55230         1           0                 0                 1                 0\n",
      "2   28  33.000         3   4449.46200         1           0                 0                 1                 0\n",
      "3   33  22.705         0  21984.47061         1           0                 1                 0                 0\n",
      "4   32  28.880         0   3866.85520         1           0                 1                 0                 0\n"
     ]
    }
   ],
   "source": [
    "#EX-96:Convert all categorical variables to 0-1 encoding and assign it to df_dummies \n",
    "pd.set_option('max_columns', 15)\n",
    "pd.set_option('display.width', 150)\n",
    "url = 'https://storage.googleapis.com/esmartdata-courses-files/ml-course/insurance.csv'\n",
    "df = pd.read_csv(url)\n",
    "for col in list(df.select_dtypes(include=['object']).columns):\n",
    "    df[col] = df[col].astype('category')\n",
    "df_dummies = pd.get_dummies(df, drop_first=True)\n",
    "print(df_dummies.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       age       bmi  children   charges  sex_male  smoker_yes  region_northwest  region_southeast  region_southwest\n",
      "age               1.000000  0.109272  0.042469  0.299008 -0.020856   -0.025019         -0.000407         -0.011642          0.010016\n",
      "bmi               0.109272  1.000000  0.012759  0.198341  0.046371    0.003750         -0.135996          0.270025         -0.006205\n",
      "children          0.042469  0.012759  1.000000  0.067998  0.017163    0.007673          0.024806         -0.023066          0.021914\n",
      "charges           0.299008  0.198341  0.067998  1.000000  0.057292    0.787251         -0.039905          0.073982         -0.043210\n",
      "sex_male         -0.020856  0.046371  0.017163  0.057292  1.000000    0.076185         -0.011156          0.017117         -0.004184\n",
      "smoker_yes       -0.025019  0.003750  0.007673  0.787251  0.076185    1.000000         -0.036945          0.068498         -0.036945\n",
      "region_northwest -0.000407 -0.135996  0.024806 -0.039905 -0.011156   -0.036945          1.000000         -0.346265         -0.320829\n",
      "region_southeast -0.011642  0.270025 -0.023066  0.073982  0.017117    0.068498         -0.346265          1.000000         -0.346265\n",
      "region_southwest  0.010016 -0.006205  0.021914 -0.043210 -0.004184   -0.036945         -0.320829         -0.346265          1.000000\n"
     ]
    }
   ],
   "source": [
    "#EX-97:Calculate the correlations of columns in df_dummies and assign it to carr variables\n",
    "\n",
    "pd.set_option('max_columns', 15)\n",
    "pd.set_option('display.width', 150)\n",
    "url = 'https://storage.googleapis.com/esmartdata-courses-files/ml-course/insurance.csv'\n",
    "df = pd.read_csv(url)\n",
    "for col in list(df.select_dtypes(include=['object']).columns):\n",
    "    df[col] = df[col].astype('category')\n",
    "df_dummies = pd.get_dummies(df, drop_first=True)\n",
    "corr = df_dummies.corr()\n",
    "print(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   charges\n",
      "charges           1.000000\n",
      "smoker_yes        0.787251\n",
      "age               0.299008\n",
      "bmi               0.198341\n",
      "region_southeast  0.073982\n",
      "children          0.067998\n",
      "sex_male          0.057292\n",
      "region_northwest -0.039905\n",
      "region_southwest -0.043210\n"
     ]
    }
   ],
   "source": [
    "#EX-98: Extract charge column , sort the values in descending orders\n",
    "pd.set_option('max_columns', 15)\n",
    "pd.set_option('display.width', 150)\n",
    "url = 'https://storage.googleapis.com/esmartdata-courses-files/ml-course/insurance.csv'\n",
    "df = pd.read_csv(url)\n",
    "for col in list(df.select_dtypes(include=['object']).columns):\n",
    "    df[col] = df[col].astype('category')\n",
    "df_dummies = pd.get_dummies(df, drop_first=True)\n",
    "corr = df_dummies.corr()\n",
    "print(corr[['charges']].sort_values(by='charges', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age     bmi  children  sex_male  smoker_yes  region_northwest  region_southeast  region_southwest\n",
      "0   19  27.900         0         0           1                 0                 0                 1\n",
      "1   18  33.770         1         1           0                 0                 1                 0\n",
      "2   28  33.000         3         1           0                 0                 1                 0\n",
      "3   33  22.705         0         1           0                 1                 0                 0\n",
      "4   32  28.880         0         1           0                 1                 0                 0\n",
      "\n",
      "0    16884.92400\n",
      "1     1725.55230\n",
      "2     4449.46200\n",
      "3    21984.47061\n",
      "4     3866.85520\n",
      "Name: charges, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#EX-99:Make a copy of df_dummies and assign to data variable. Then pop the charge column from this object and assign it to target variable\n",
    "pd.set_option('max_columns', 15)\n",
    "pd.set_option('display.width', 150)\n",
    "url = 'https://storage.googleapis.com/esmartdata-courses-files/ml-course/insurance.csv'\n",
    "df = pd.read_csv(url)\n",
    "for col in list(df.select_dtypes(include=['object']).columns):\n",
    "    df[col] = df[col].astype('category')\n",
    "df_dummies = pd.get_dummies(df, drop_first=True)\n",
    "data = df_dummies.copy()\n",
    "target = data.pop('charges')\n",
    "print(data.head())\n",
    "print()\n",
    "print(target.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  size  color  gender  price  weight bought\n",
      "0   XL    red  female  199.0     500    yes\n",
      "1    L  green    male   89.0     450     no\n",
      "2    M   blue    male   99.0     300    yes\n",
      "3    L  green  female  129.0     380     no\n",
      "4    M    red  female   79.0     410    yes\n"
     ]
    }
   ],
   "source": [
    "#EX-100: Create the dataframe from the following dictionary and assign it to df variable\n",
    "data = {\n",
    "    'size': ['XL', 'L', 'M', 'L', 'M'],\n",
    "    'color': ['red', 'green', 'blue', 'green', 'red'],\n",
    "    'gender': ['female', 'male', 'male', 'female', 'female'],\n",
    "    'price': [199.0, 89.0, 99.0, 129.0, 79.0],\n",
    "    'weight': [500, 450, 300, 380, 410],\n",
    "    'bought': ['yes', 'no', 'yes', 'no', 'yes']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5 entries, 0 to 4\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Non-Null Count  Dtype   \n",
      "---  ------  --------------  -----   \n",
      " 0   size    5 non-null      category\n",
      " 1   color   5 non-null      category\n",
      " 2   gender  5 non-null      category\n",
      " 3   price   5 non-null      float64 \n",
      " 4   weight  5 non-null      float64 \n",
      " 5   bought  5 non-null      category\n",
      "dtypes: category(4), float64(2)\n",
      "memory usage: 628.0 bytes\n"
     ]
    }
   ],
   "source": [
    "#EX-101: Convert columns size, color, gender, bought to category and weight to float\n",
    "data = {\n",
    "    'size': ['XL', 'L', 'M', 'L', 'M'],\n",
    "    'color': ['red', 'green', 'blue', 'green', 'red'],\n",
    "    'gender': ['female', 'male', 'male', 'female', 'female'],\n",
    "    'price': [199.0, 89.0, 99.0, 129.0, 79.0],\n",
    "    'weight': [500, 450, 300, 380, 410],\n",
    "    'bought': ['yes', 'no', 'yes', 'no', 'yes']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "for col in ['size', 'color', 'gender', 'bought']:\n",
    "    df[col] = df[col].astype('category')\n",
    " \n",
    "df['weight'] = df['weight'].astype('float')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   price  weight  size_L  size_M  size_XL  color_blue  color_green  color_red  gender_female  gender_male  bought_no  bought_yes\n",
      "0  199.0   500.0       0       0        1           0            0          1              1            0          0           1\n",
      "1   89.0   450.0       1       0        0           0            1          0              0            1          1           0\n",
      "2   99.0   300.0       0       1        0           1            0          0              0            1          0           1\n",
      "3  129.0   380.0       1       0        0           0            1          0              1            0          1           0\n",
      "4   79.0   410.0       0       1        0           0            0          1              1            0          0           1\n"
     ]
    }
   ],
   "source": [
    "#EX-102: Transform all categorical variables 0-1 encoding\n",
    "pd.set_option('max_columns', 15)\n",
    "pd.set_option('display.width', 150)\n",
    "data = {\n",
    "    'size': ['XL', 'L', 'M', 'L', 'M'],\n",
    "    'color': ['red', 'green', 'blue', 'green', 'red'],\n",
    "    'gender': ['female', 'male', 'male', 'female', 'female'],\n",
    "    'price': [199.0, 89.0, 99.0, 129.0, 79.0],\n",
    "    'weight': [500, 450, 300, 380, 410],\n",
    "    'bought': ['yes', 'no', 'yes', 'no', 'yes']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "for col in ['size', 'color', 'gender', 'bought']:\n",
    "    df[col] = df[col].astype('category')\n",
    "\n",
    "df['weight'] = df['weight'].astype('float')\n",
    "print(pd.get_dummies(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   price  weight  size_M  size_XL  color_green  color_red  gender_male  bought_yes\n",
      "0  199.0   500.0       0        1            0          1            0           1\n",
      "1   89.0   450.0       0        0            1          0            1           0\n",
      "2   99.0   300.0       1        0            0          0            1           1\n",
      "3  129.0   380.0       0        0            1          0            0           0\n",
      "4   79.0   410.0       1        0            0          1            0           1\n"
     ]
    }
   ],
   "source": [
    "#EX-103:Transform all categorical variables 0-1 encoding\n",
    "pd.set_option('max_columns', 15)\n",
    "pd.set_option('display.width', 150)\n",
    "data = {\n",
    "    'size': ['XL', 'L', 'M', 'L', 'M'],\n",
    "    'color': ['red', 'green', 'blue', 'green', 'red'],\n",
    "    'gender': ['female', 'male', 'male', 'female', 'female'],\n",
    "    'price': [199.0, 89.0, 99.0, 129.0, 79.0],\n",
    "    'weight': [500, 450, 300, 380, 410],\n",
    "    'bought': ['yes', 'no', 'yes', 'no', 'yes']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "for col in ['size', 'color', 'gender', 'bought']:\n",
    "    df[col] = df[col].astype('category')\n",
    "\n",
    "df['weight'] = df['weight'].astype('float')\n",
    "print(pd.get_dummies(df, drop_first=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       profile   time     price  change pct_change  reference_price      open       low      high\n",
      "0              ^AEX (Holandia)  14:12    548.73    7.95   (+1.47%)           540.78    546.55    544.72    550.72\n",
      "1               ^ATX (Austria)  14:11   2147.90   17.68   (+0.83%)          2130.22   2131.47   2118.71   2163.92\n",
      "2               ^ATXC (Grecja)  14:13    621.82   -2.80   (-0.45%)           624.62    627.48    621.82    631.70\n",
      "3              ^BEL20 (Belgia)  14:11   3251.39   30.51   (+0.95%)          3220.88   3252.21   3228.77   3266.11\n",
      "4                 ^BUX (Węgry)  14:12  32831.01  534.27   (+1.65%)         32296.74  32421.05  32421.05  32865.43\n",
      "5             ^CAC40 (Francja)  14:12   4839.46   66.62   (+1.40%)          4772.84   4824.17   4803.91   4871.45\n",
      "6                ^DAX (Niemcy)  14:14  12758.52  164.13   (+1.30%)         12594.39  12737.32  12688.33  12830.70\n",
      "7   ^FTSE100 (Wielka Brytania)  14:12   5945.44  115.98   (+1.99%)          5829.46   5829.46   5829.46   5974.88\n",
      "8   ^FTSE250 (Wielka Brytania)  14:12  17038.88  217.22   (+1.29%)         16821.66  16821.66  16821.66  17123.31\n",
      "9            ^FTSEMIB (Włochy)  14:12  19080.16  184.57   (+0.98%)         18895.59  19080.18  18944.29  19231.99\n",
      "10         ^IBEX35 (Hiszpania)  14:12   6755.80  107.20   (+1.61%)          6648.60   6717.80   6681.60   6781.10\n",
      "11             ^OMXC20 (Dania)  14:27   1336.57    0.58   (+0.04%)          1335.99   1338.82   1322.42   1338.82\n",
      "12         ^OMXH25 (Finlandia)  14:26  10037.06   21.87   (+0.22%)         10015.19  10052.81  10024.27  10107.86\n",
      "13           ^OMXS30 (Szwecja)  14:27   1802.43   20.51   (+1.15%)          1781.92   1791.67   1789.70   1814.53\n",
      "14           ^OSEAX (Norwegia)  14:12    739.99    1.36   (+0.18%)           738.63    738.46    738.03    744.44\n",
      "15         ^PSI20 (Portugalia)  14:13   4119.97   -1.97   (-0.05%)          4121.94   4141.19   4119.97   4156.11\n",
      "16              ^PX50 (Czechy)  14:12    870.57    2.52   (+0.29%)           868.05    868.53    862.45    873.37\n",
      "17             ^RDXEUR (Rosja)  14:11   1264.48    2.21   (+0.18%)          1262.27   1263.78   1259.57   1274.42\n",
      "18                ^RTS (Rosja)  14:11   1524.18   -2.09   (-0.14%)          1526.27   1526.27   1521.70   1541.51\n",
      "19           ^SMI (Szwajcaria)  14:11  10371.42   15.85   (+0.15%)         10355.57  10368.65  10334.54  10439.74\n",
      "20             ^XU100 (Turcja)  14:12   1104.41    8.25   (+0.75%)          1096.16   1101.04   1098.82   1106.06\n",
      "21              WIG20 (Polska)  14:29   1695.96    2.87   (+0.17%)          1693.09   1701.26   1695.36   1712.27\n"
     ]
    }
   ],
   "source": [
    "#EX-104: Load this market.json file and stored into df variable\n",
    "pd.set_option('display.max_columns', 15)\n",
    "pd.set_option('display.width', 1000)\n",
    "df = pd.read_json('market.json')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       profile   time     price  change pct_change  reference_price      open       low      high          country\n",
      "0              ^AEX (Holandia)  14:12    548.73    7.95   (+1.47%)           540.78    546.55    544.72    550.72         Holandia\n",
      "1               ^ATX (Austria)  14:11   2147.90   17.68   (+0.83%)          2130.22   2131.47   2118.71   2163.92          Austria\n",
      "2               ^ATXC (Grecja)  14:13    621.82   -2.80   (-0.45%)           624.62    627.48    621.82    631.70           Grecja\n",
      "3              ^BEL20 (Belgia)  14:11   3251.39   30.51   (+0.95%)          3220.88   3252.21   3228.77   3266.11           Belgia\n",
      "4                 ^BUX (Węgry)  14:12  32831.01  534.27   (+1.65%)         32296.74  32421.05  32421.05  32865.43            Węgry\n",
      "5             ^CAC40 (Francja)  14:12   4839.46   66.62   (+1.40%)          4772.84   4824.17   4803.91   4871.45          Francja\n",
      "6                ^DAX (Niemcy)  14:14  12758.52  164.13   (+1.30%)         12594.39  12737.32  12688.33  12830.70           Niemcy\n",
      "7   ^FTSE100 (Wielka Brytania)  14:12   5945.44  115.98   (+1.99%)          5829.46   5829.46   5829.46   5974.88  Wielka Brytania\n",
      "8   ^FTSE250 (Wielka Brytania)  14:12  17038.88  217.22   (+1.29%)         16821.66  16821.66  16821.66  17123.31  Wielka Brytania\n",
      "9            ^FTSEMIB (Włochy)  14:12  19080.16  184.57   (+0.98%)         18895.59  19080.18  18944.29  19231.99           Włochy\n",
      "10         ^IBEX35 (Hiszpania)  14:12   6755.80  107.20   (+1.61%)          6648.60   6717.80   6681.60   6781.10        Hiszpania\n",
      "11             ^OMXC20 (Dania)  14:27   1336.57    0.58   (+0.04%)          1335.99   1338.82   1322.42   1338.82            Dania\n",
      "12         ^OMXH25 (Finlandia)  14:26  10037.06   21.87   (+0.22%)         10015.19  10052.81  10024.27  10107.86        Finlandia\n",
      "13           ^OMXS30 (Szwecja)  14:27   1802.43   20.51   (+1.15%)          1781.92   1791.67   1789.70   1814.53          Szwecja\n",
      "14           ^OSEAX (Norwegia)  14:12    739.99    1.36   (+0.18%)           738.63    738.46    738.03    744.44         Norwegia\n",
      "15         ^PSI20 (Portugalia)  14:13   4119.97   -1.97   (-0.05%)          4121.94   4141.19   4119.97   4156.11       Portugalia\n",
      "16              ^PX50 (Czechy)  14:12    870.57    2.52   (+0.29%)           868.05    868.53    862.45    873.37           Czechy\n",
      "17             ^RDXEUR (Rosja)  14:11   1264.48    2.21   (+0.18%)          1262.27   1263.78   1259.57   1274.42            Rosja\n",
      "18                ^RTS (Rosja)  14:11   1524.18   -2.09   (-0.14%)          1526.27   1526.27   1521.70   1541.51            Rosja\n",
      "19           ^SMI (Szwajcaria)  14:11  10371.42   15.85   (+0.15%)         10355.57  10368.65  10334.54  10439.74       Szwajcaria\n",
      "20             ^XU100 (Turcja)  14:12   1104.41    8.25   (+0.75%)          1096.16   1101.04   1098.82   1106.06           Turcja\n",
      "21              WIG20 (Polska)  14:29   1695.96    2.87   (+0.17%)          1693.09   1701.26   1695.36   1712.27           Polska\n"
     ]
    }
   ],
   "source": [
    "#EX-105:Extract country_name from the first column and assign it to country\n",
    "pd.set_option('display.max_columns', 15)\n",
    "pd.set_option('display.width', 1000)\n",
    "df = pd.read_json('market.json')\n",
    "df['country'] = df['profile'].str.split(n=1, expand=True)[1].apply(lambda item: item[1:-1])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Rosja', 'Wielka Brytania']\n"
     ]
    }
   ],
   "source": [
    "#EX-106: Extract country names that occurs more than once as a list\n",
    "pd.set_option('display.max_columns', 15)\n",
    "pd.set_option('display.width', 1000)\n",
    "df = pd.read_json('market.json')\n",
    "df['country'] = df['profile'].str.split(n=1, expand=True)[1].apply(lambda item: item[1:-1])\n",
    "print(sorted(df['country'].value_counts()[df['country'].value_counts() > 1].index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       profile   time     price  change  pct_change  reference_price      open       low      high\n",
      "0              ^AEX (Holandia)  14:12    548.73    7.95        1.47           540.78    546.55    544.72    550.72\n",
      "1               ^ATX (Austria)  14:11   2147.90   17.68        0.83          2130.22   2131.47   2118.71   2163.92\n",
      "2               ^ATXC (Grecja)  14:13    621.82   -2.80       -0.45           624.62    627.48    621.82    631.70\n",
      "3              ^BEL20 (Belgia)  14:11   3251.39   30.51        0.95          3220.88   3252.21   3228.77   3266.11\n",
      "4                 ^BUX (Węgry)  14:12  32831.01  534.27        1.65         32296.74  32421.05  32421.05  32865.43\n",
      "5             ^CAC40 (Francja)  14:12   4839.46   66.62        1.40          4772.84   4824.17   4803.91   4871.45\n",
      "6                ^DAX (Niemcy)  14:14  12758.52  164.13        1.30         12594.39  12737.32  12688.33  12830.70\n",
      "7   ^FTSE100 (Wielka Brytania)  14:12   5945.44  115.98        1.99          5829.46   5829.46   5829.46   5974.88\n",
      "8   ^FTSE250 (Wielka Brytania)  14:12  17038.88  217.22        1.29         16821.66  16821.66  16821.66  17123.31\n",
      "9            ^FTSEMIB (Włochy)  14:12  19080.16  184.57        0.98         18895.59  19080.18  18944.29  19231.99\n",
      "10         ^IBEX35 (Hiszpania)  14:12   6755.80  107.20        1.61          6648.60   6717.80   6681.60   6781.10\n",
      "11             ^OMXC20 (Dania)  14:27   1336.57    0.58        0.04          1335.99   1338.82   1322.42   1338.82\n",
      "12         ^OMXH25 (Finlandia)  14:26  10037.06   21.87        0.22         10015.19  10052.81  10024.27  10107.86\n",
      "13           ^OMXS30 (Szwecja)  14:27   1802.43   20.51        1.15          1781.92   1791.67   1789.70   1814.53\n",
      "14           ^OSEAX (Norwegia)  14:12    739.99    1.36        0.18           738.63    738.46    738.03    744.44\n",
      "15         ^PSI20 (Portugalia)  14:13   4119.97   -1.97       -0.05          4121.94   4141.19   4119.97   4156.11\n",
      "16              ^PX50 (Czechy)  14:12    870.57    2.52        0.29           868.05    868.53    862.45    873.37\n",
      "17             ^RDXEUR (Rosja)  14:11   1264.48    2.21        0.18          1262.27   1263.78   1259.57   1274.42\n",
      "18                ^RTS (Rosja)  14:11   1524.18   -2.09       -0.14          1526.27   1526.27   1521.70   1541.51\n",
      "19           ^SMI (Szwajcaria)  14:11  10371.42   15.85        0.15         10355.57  10368.65  10334.54  10439.74\n",
      "20             ^XU100 (Turcja)  14:12   1104.41    8.25        0.75          1096.16   1101.04   1098.82   1106.06\n",
      "21              WIG20 (Polska)  14:29   1695.96    2.87        0.17          1693.09   1701.26   1695.36   1712.27\n"
     ]
    }
   ],
   "source": [
    "#EX-107: convert column pct_change to float type\n",
    "\n",
    "pd.set_option('display.max_columns', 15)\n",
    "pd.set_option('display.width', 1000)\n",
    "df = pd.read_json('market.json')\n",
    "df['pct_change'] = df['pct_change'].apply(lambda item: float(item[1:-2]))\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "profile            ^FTSE100 (Wielka Brytania)\n",
      "time                                    14:12\n",
      "price                                 5945.44\n",
      "change                                 115.98\n",
      "pct_change                               1.99\n",
      "reference_price                       5829.46\n",
      "open                                  5829.46\n",
      "low                                   5829.46\n",
      "high                                  5974.88\n",
      "Name: 7, dtype: object\n",
      "\n",
      "profile            ^ATXC (Grecja)\n",
      "time                        14:13\n",
      "price                      621.82\n",
      "change                       -2.8\n",
      "pct_change                  -0.45\n",
      "reference_price            624.62\n",
      "open                       627.48\n",
      "low                        621.82\n",
      "high                        631.7\n",
      "Name: 2, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#EX-108:Print highest pct_change, blank line and lowest pct_change\n",
    "pd.set_option('display.max_columns', 15)\n",
    "pd.set_option('display.width', 1000)\n",
    "df = pd.read_json('market.json')\n",
    "df['pct_change'] = df['pct_change'].apply(lambda item: float(item[1:-2]))\n",
    "print(df.iloc[df['pct_change'].argmax()])\n",
    "print()\n",
    "print(df.iloc[df['pct_change'].argmin()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EX-109:Extract all rows pct_change column is greater than or equal to zero and save to positive.json do the same for negative values and save it to negative.json\n",
    "pd.set_option('display.max_columns', 15)\n",
    "pd.set_option('display.width', 1000)\n",
    "df = pd.read_json('market.json')\n",
    "df['pct_change'] = df['pct_change'].apply(lambda item: float(item[1:-2]))\n",
    "df[df['pct_change'] >= 0].to_json('positive.json', indent=4)\n",
    "df[df['pct_change'] < 0].to_json('negative.json', indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Open       High        Low    Close   Volume\n",
      "Date                                                         \n",
      "2020-09-22  3033.8350  3133.9900  3000.2000  3128.99  6948816\n",
      "2020-09-21  2906.5000  2962.0000  2871.0000  2960.47  6117925\n",
      "2020-09-18  3031.7400  3037.8000  2905.5400  2954.91  8892580\n",
      "2020-09-17  3009.2500  3029.4320  2972.5500  3008.73  6449050\n",
      "2020-09-16  3179.9900  3187.2380  3074.1500  3078.10  4531189\n",
      "2020-09-15  3136.1600  3175.0200  3108.9200  3156.13  4021535\n",
      "2020-09-14  3172.9372  3187.3900  3096.0000  3102.97  4529596\n",
      "2020-09-11  3208.6900  3217.3409  3083.9800  3116.22  5093982\n",
      "2020-09-10  3307.2188  3349.8900  3170.5500  3175.11  5330741\n",
      "2020-09-09  3202.9900  3303.1750  3185.0000  3268.61  5188675\n",
      "2020-09-08  3144.0000  3250.8450  3130.0000  3149.84  6094205\n",
      "2020-09-04  3318.0000  3381.5000  3111.1300  3294.62  8781754\n",
      "2020-09-03  3485.0000  3488.4100  3303.0000  3368.00  8161113\n",
      "2020-09-02  3547.0000  3552.2500  3486.6850  3531.45  3931476\n",
      "2020-09-01  3489.5800  3513.8700  3467.0000  3499.12  3476407\n",
      "2020-08-31  3408.9900  3495.0000  3405.0000  3450.96  4185885\n",
      "2020-08-28  3423.0000  3433.3699  3386.5000  3401.80  2896978\n",
      "2020-08-27  3450.0500  3453.0000  3378.0000  3400.00  4264795\n",
      "2020-08-26  3351.1100  3451.7387  3344.5675  3441.85  6508743\n",
      "2020-08-25  3294.9900  3357.4000  3267.0000  3346.49  3992842\n",
      "\n",
      "              Open    High       Low   Close     Volume\n",
      "Date                                                   \n",
      "2020-09-22  429.60  437.76  417.6001  424.23   79580795\n",
      "2020-09-21  453.13  455.68  407.0700  449.39  109476800\n",
      "2020-09-18  447.94  451.00  428.8000  442.15   86406819\n",
      "2020-09-17  415.60  437.79  408.0001  423.43   76779163\n",
      "2020-09-16  439.87  457.79  435.3100  441.76   72546760\n",
      "2020-09-15  436.56  461.94  430.7000  449.76   97298228\n",
      "2020-09-14  380.95  420.00  373.3000  419.62   83020608\n",
      "2020-09-11  381.94  382.50  360.5000  372.72   60717459\n",
      "2020-09-10  386.21  398.99  360.5600  371.34   84930608\n",
      "2020-09-09  356.60  369.00  341.5100  366.28   79465769\n",
      "2020-09-08  356.00  368.74  329.8800  330.21  115465691\n",
      "2020-09-04  402.81  428.00  372.0201  418.32  110321885\n",
      "2020-09-03  407.23  431.80  402.0000  407.00   87596086\n",
      "2020-09-02  478.99  479.04  405.1206  447.37   96176128\n",
      "2020-09-01  502.14  502.49  470.5100  475.05   90119419\n",
      "2020-08-31  444.61  500.14  440.1100  498.32  118374406\n",
      "2020-08-28  459.02  463.70  437.3000  442.68  100405880\n",
      "2020-08-27  436.09  459.12  428.5000  447.75  118465215\n",
      "2020-08-26  412.00  433.20  410.7300  430.63   71196910\n",
      "2020-08-25  394.98  405.59  393.6000  404.67   53294465\n"
     ]
    }
   ],
   "source": [
    "#EX-110: Load data from amazon.csv and tesla.csv\n",
    "amazon = pd.read_csv('amazon.csv', index_col=0)\n",
    "tesla = pd.read_csv('tesla.csv', index_col=0)\n",
    "print(amazon)\n",
    "print()\n",
    "print(tesla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            amzn_open  amzn_high   amzn_low  amzn_close  amzn_volume\n",
      "Date                                                                \n",
      "2020-09-22  3033.8350  3133.9900  3000.2000     3128.99      6948816\n",
      "2020-09-21  2906.5000  2962.0000  2871.0000     2960.47      6117925\n",
      "2020-09-18  3031.7400  3037.8000  2905.5400     2954.91      8892580\n",
      "2020-09-17  3009.2500  3029.4320  2972.5500     3008.73      6449050\n",
      "2020-09-16  3179.9900  3187.2380  3074.1500     3078.10      4531189\n",
      "2020-09-15  3136.1600  3175.0200  3108.9200     3156.13      4021535\n",
      "2020-09-14  3172.9372  3187.3900  3096.0000     3102.97      4529596\n",
      "2020-09-11  3208.6900  3217.3409  3083.9800     3116.22      5093982\n",
      "2020-09-10  3307.2188  3349.8900  3170.5500     3175.11      5330741\n",
      "2020-09-09  3202.9900  3303.1750  3185.0000     3268.61      5188675\n",
      "2020-09-08  3144.0000  3250.8450  3130.0000     3149.84      6094205\n",
      "2020-09-04  3318.0000  3381.5000  3111.1300     3294.62      8781754\n",
      "2020-09-03  3485.0000  3488.4100  3303.0000     3368.00      8161113\n",
      "2020-09-02  3547.0000  3552.2500  3486.6850     3531.45      3931476\n",
      "2020-09-01  3489.5800  3513.8700  3467.0000     3499.12      3476407\n",
      "2020-08-31  3408.9900  3495.0000  3405.0000     3450.96      4185885\n",
      "2020-08-28  3423.0000  3433.3699  3386.5000     3401.80      2896978\n",
      "2020-08-27  3450.0500  3453.0000  3378.0000     3400.00      4264795\n",
      "2020-08-26  3351.1100  3451.7387  3344.5675     3441.85      6508743\n",
      "2020-08-25  3294.9900  3357.4000  3267.0000     3346.49      3992842\n",
      "\n",
      "            tsla_open  tsla_high  tsla_low  tsla_close  tsla_volume\n",
      "Date                                                               \n",
      "2020-09-22     429.60     437.76  417.6001      424.23     79580795\n",
      "2020-09-21     453.13     455.68  407.0700      449.39    109476800\n",
      "2020-09-18     447.94     451.00  428.8000      442.15     86406819\n",
      "2020-09-17     415.60     437.79  408.0001      423.43     76779163\n",
      "2020-09-16     439.87     457.79  435.3100      441.76     72546760\n",
      "2020-09-15     436.56     461.94  430.7000      449.76     97298228\n",
      "2020-09-14     380.95     420.00  373.3000      419.62     83020608\n",
      "2020-09-11     381.94     382.50  360.5000      372.72     60717459\n",
      "2020-09-10     386.21     398.99  360.5600      371.34     84930608\n",
      "2020-09-09     356.60     369.00  341.5100      366.28     79465769\n",
      "2020-09-08     356.00     368.74  329.8800      330.21    115465691\n",
      "2020-09-04     402.81     428.00  372.0201      418.32    110321885\n",
      "2020-09-03     407.23     431.80  402.0000      407.00     87596086\n",
      "2020-09-02     478.99     479.04  405.1206      447.37     96176128\n",
      "2020-09-01     502.14     502.49  470.5100      475.05     90119419\n",
      "2020-08-31     444.61     500.14  440.1100      498.32    118374406\n",
      "2020-08-28     459.02     463.70  437.3000      442.68    100405880\n",
      "2020-08-27     436.09     459.12  428.5000      447.75    118465215\n",
      "2020-08-26     412.00     433.20  410.7300      430.63     71196910\n",
      "2020-08-25     394.98     405.59  393.6000      404.67     53294465\n"
     ]
    }
   ],
   "source": [
    "#EX-111:Replace column name by adding prefix 'amzn' to each column in amazon and prefix 'tsla' to each column on tesla. Also converts uppercase to lowercase\n",
    "amazon = pd.read_csv('amazon.csv', index_col=0)\n",
    "tesla = pd.read_csv('tesla.csv', index_col=0)\n",
    "amazon.columns = ['amzn_' + col.lower() for col in amazon.columns]\n",
    "tesla.columns = ['tsla_' + col.lower() for col in tesla.columns]\n",
    "print(amazon)\n",
    "print()\n",
    "print(tesla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            amzn_open  amzn_high   amzn_low  amzn_close  amzn_volume  tsla_open  tsla_high  tsla_low  tsla_close  tsla_volume\n",
      "Date                                                                                                                         \n",
      "2020-09-22  3033.8350  3133.9900  3000.2000     3128.99      6948816     429.60     437.76  417.6001      424.23     79580795\n",
      "2020-09-21  2906.5000  2962.0000  2871.0000     2960.47      6117925     453.13     455.68  407.0700      449.39    109476800\n",
      "2020-09-18  3031.7400  3037.8000  2905.5400     2954.91      8892580     447.94     451.00  428.8000      442.15     86406819\n",
      "2020-09-17  3009.2500  3029.4320  2972.5500     3008.73      6449050     415.60     437.79  408.0001      423.43     76779163\n",
      "2020-09-16  3179.9900  3187.2380  3074.1500     3078.10      4531189     439.87     457.79  435.3100      441.76     72546760\n",
      "2020-09-15  3136.1600  3175.0200  3108.9200     3156.13      4021535     436.56     461.94  430.7000      449.76     97298228\n",
      "2020-09-14  3172.9372  3187.3900  3096.0000     3102.97      4529596     380.95     420.00  373.3000      419.62     83020608\n",
      "2020-09-11  3208.6900  3217.3409  3083.9800     3116.22      5093982     381.94     382.50  360.5000      372.72     60717459\n",
      "2020-09-10  3307.2188  3349.8900  3170.5500     3175.11      5330741     386.21     398.99  360.5600      371.34     84930608\n",
      "2020-09-09  3202.9900  3303.1750  3185.0000     3268.61      5188675     356.60     369.00  341.5100      366.28     79465769\n",
      "2020-09-08  3144.0000  3250.8450  3130.0000     3149.84      6094205     356.00     368.74  329.8800      330.21    115465691\n",
      "2020-09-04  3318.0000  3381.5000  3111.1300     3294.62      8781754     402.81     428.00  372.0201      418.32    110321885\n",
      "2020-09-03  3485.0000  3488.4100  3303.0000     3368.00      8161113     407.23     431.80  402.0000      407.00     87596086\n",
      "2020-09-02  3547.0000  3552.2500  3486.6850     3531.45      3931476     478.99     479.04  405.1206      447.37     96176128\n",
      "2020-09-01  3489.5800  3513.8700  3467.0000     3499.12      3476407     502.14     502.49  470.5100      475.05     90119419\n",
      "2020-08-31  3408.9900  3495.0000  3405.0000     3450.96      4185885     444.61     500.14  440.1100      498.32    118374406\n",
      "2020-08-28  3423.0000  3433.3699  3386.5000     3401.80      2896978     459.02     463.70  437.3000      442.68    100405880\n",
      "2020-08-27  3450.0500  3453.0000  3378.0000     3400.00      4264795     436.09     459.12  428.5000      447.75    118465215\n",
      "2020-08-26  3351.1100  3451.7387  3344.5675     3441.85      6508743     412.00     433.20  410.7300      430.63     71196910\n",
      "2020-08-25  3294.9900  3357.4000  3267.0000     3346.49      3992842     394.98     405.59  393.6000      404.67     53294465\n"
     ]
    }
   ],
   "source": [
    "#EX-112: Combine amazon and tesla two objects into one dataframes\n",
    "pd.set_option('display.max_columns', 30)\n",
    "pd.set_option('display.width', 1000)\n",
    " \n",
    "amazon = pd.read_csv('amazon.csv', index_col=0)\n",
    "tesla = pd.read_csv('tesla.csv', index_col=0)\n",
    "amazon.columns = ['amzn_' + col.lower() for col in amazon.columns]\n",
    "tesla.columns = ['tsla_' + col.lower() for col in tesla.columns]\n",
    "result = pd.concat([amazon, tesla], axis=1)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            amzn_open  amzn_close  tsla_open  tsla_close\n",
      "Date                                                    \n",
      "2020-09-22  3033.8350     3128.99     429.60      424.23\n",
      "2020-09-21  2906.5000     2960.47     453.13      449.39\n",
      "2020-09-18  3031.7400     2954.91     447.94      442.15\n",
      "2020-09-17  3009.2500     3008.73     415.60      423.43\n",
      "2020-09-16  3179.9900     3078.10     439.87      441.76\n",
      "2020-09-15  3136.1600     3156.13     436.56      449.76\n",
      "2020-09-14  3172.9372     3102.97     380.95      419.62\n",
      "2020-09-11  3208.6900     3116.22     381.94      372.72\n",
      "2020-09-10  3307.2188     3175.11     386.21      371.34\n",
      "2020-09-09  3202.9900     3268.61     356.60      366.28\n",
      "2020-09-08  3144.0000     3149.84     356.00      330.21\n",
      "2020-09-04  3318.0000     3294.62     402.81      418.32\n",
      "2020-09-03  3485.0000     3368.00     407.23      407.00\n",
      "2020-09-02  3547.0000     3531.45     478.99      447.37\n",
      "2020-09-01  3489.5800     3499.12     502.14      475.05\n",
      "2020-08-31  3408.9900     3450.96     444.61      498.32\n",
      "2020-08-28  3423.0000     3401.80     459.02      442.68\n",
      "2020-08-27  3450.0500     3400.00     436.09      447.75\n",
      "2020-08-26  3351.1100     3441.85     412.00      430.63\n",
      "2020-08-25  3294.9900     3346.49     394.98      404.67\n"
     ]
    }
   ],
   "source": [
    "#EX-113: Extract columns amzn_open, amzn_close, tsla_open, tsla_close\n",
    "pd.set_option('display.max_columns', 30)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "amazon = pd.read_csv('amazon.csv', index_col=0)\n",
    "tesla = pd.read_csv('tesla.csv', index_col=0)\n",
    "amazon.columns = ['amzn_' + col.lower() for col in amazon.columns]\n",
    "tesla.columns = ['tsla_' + col.lower() for col in tesla.columns]\n",
    "result = pd.concat([amazon, tesla], axis=1)\n",
    "quotations = result[['amzn_open', 'amzn_close', 'tsla_open', 'tsla_close']].copy()\n",
    "print(quotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            amzn_open  amzn_close  tsla_open  tsla_close  amzn_change  tsla_change\n",
      "Date                                                                              \n",
      "2020-09-22  3033.8350     3128.99     429.60      424.23     3.136459    -1.250000\n",
      "2020-09-21  2906.5000     2960.47     453.13      449.39     1.856873    -0.825370\n",
      "2020-09-18  3031.7400     2954.91     447.94      442.15    -2.534188    -1.292584\n",
      "2020-09-17  3009.2500     3008.73     415.60      423.43    -0.017280     1.884023\n",
      "2020-09-16  3179.9900     3078.10     439.87      441.76    -3.204098     0.429672\n",
      "2020-09-15  3136.1600     3156.13     436.56      449.76     0.636766     3.023639\n",
      "2020-09-14  3172.9372     3102.97     380.95      419.62    -2.205124    10.150938\n",
      "2020-09-11  3208.6900     3116.22     381.94      372.72    -2.881861    -2.413992\n",
      "2020-09-10  3307.2188     3175.11     386.21      371.34    -3.994559    -3.850237\n",
      "2020-09-09  3202.9900     3268.61     356.60      366.28     2.048711     2.714526\n",
      "2020-09-08  3144.0000     3149.84     356.00      330.21     0.185751    -7.244382\n",
      "2020-09-04  3318.0000     3294.62     402.81      418.32    -0.704641     3.850451\n",
      "2020-09-03  3485.0000     3368.00     407.23      407.00    -3.357245    -0.056479\n",
      "2020-09-02  3547.0000     3531.45     478.99      447.37    -0.438399    -6.601390\n",
      "2020-09-01  3489.5800     3499.12     502.14      475.05     0.273385    -5.394910\n",
      "2020-08-31  3408.9900     3450.96     444.61      498.32     1.231156    12.080250\n",
      "2020-08-28  3423.0000     3401.80     459.02      442.68    -0.619340    -3.559758\n",
      "2020-08-27  3450.0500     3400.00     436.09      447.75    -1.450704     2.673760\n",
      "2020-08-26  3351.1100     3441.85     412.00      430.63     2.707760     4.521845\n",
      "2020-08-25  3294.9900     3346.49     394.98      404.67     1.562979     2.453289\n"
     ]
    }
   ],
   "source": [
    "#EX-114: Assign two columns amzn_change, tsla_change which will be daily percentage change of price\n",
    "pd.set_option('display.max_columns', 30)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "amazon = pd.read_csv('amazon.csv', index_col=0)\n",
    "tesla = pd.read_csv('tesla.csv', index_col=0)\n",
    "amazon.columns = ['amzn_' + col.lower() for col in amazon.columns]\n",
    "tesla.columns = ['tsla_' + col.lower() for col in tesla.columns]\n",
    "result = pd.concat([amazon, tesla], axis=1)\n",
    "quotations = result[['amzn_open', 'amzn_close', 'tsla_open', 'tsla_close']].copy()\n",
    "quotations['amzn_change'] = (quotations['amzn_close'] / quotations['amzn_open'] - 1) * 100\n",
    "quotations['tsla_change'] = (quotations['tsla_close'] / quotations['tsla_open'] - 1) * 100\n",
    "print(quotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            amzn_open  amzn_close  tsla_open  tsla_close  amzn_change  tsla_change  similarity_flag\n",
      "Date                                                                                               \n",
      "2020-09-22  3033.8350     3128.99     429.60      424.23     3.136459    -1.250000                0\n",
      "2020-09-21  2906.5000     2960.47     453.13      449.39     1.856873    -0.825370                0\n",
      "2020-09-18  3031.7400     2954.91     447.94      442.15    -2.534188    -1.292584                1\n",
      "2020-09-17  3009.2500     3008.73     415.60      423.43    -0.017280     1.884023                0\n",
      "2020-09-16  3179.9900     3078.10     439.87      441.76    -3.204098     0.429672                0\n",
      "2020-09-15  3136.1600     3156.13     436.56      449.76     0.636766     3.023639                1\n",
      "2020-09-14  3172.9372     3102.97     380.95      419.62    -2.205124    10.150938                0\n",
      "2020-09-11  3208.6900     3116.22     381.94      372.72    -2.881861    -2.413992                1\n",
      "2020-09-10  3307.2188     3175.11     386.21      371.34    -3.994559    -3.850237                1\n",
      "2020-09-09  3202.9900     3268.61     356.60      366.28     2.048711     2.714526                1\n",
      "2020-09-08  3144.0000     3149.84     356.00      330.21     0.185751    -7.244382                0\n",
      "2020-09-04  3318.0000     3294.62     402.81      418.32    -0.704641     3.850451                0\n",
      "2020-09-03  3485.0000     3368.00     407.23      407.00    -3.357245    -0.056479                1\n",
      "2020-09-02  3547.0000     3531.45     478.99      447.37    -0.438399    -6.601390                1\n",
      "2020-09-01  3489.5800     3499.12     502.14      475.05     0.273385    -5.394910                0\n",
      "2020-08-31  3408.9900     3450.96     444.61      498.32     1.231156    12.080250                1\n",
      "2020-08-28  3423.0000     3401.80     459.02      442.68    -0.619340    -3.559758                1\n",
      "2020-08-27  3450.0500     3400.00     436.09      447.75    -1.450704     2.673760                0\n",
      "2020-08-26  3351.1100     3441.85     412.00      430.63     2.707760     4.521845                1\n",
      "2020-08-25  3294.9900     3346.49     394.98      404.67     1.562979     2.453289                1\n"
     ]
    }
   ],
   "source": [
    "#EX-115:Create new column similarity_flag that stores 1 when daily percentage change for amazon and tesla otherwise 0\n",
    "pd.set_option('display.max_columns', 30)\n",
    "pd.set_option('display.width', 1000)\n",
    " \n",
    "amazon = pd.read_csv('amazon.csv', index_col=0)\n",
    "tesla = pd.read_csv('tesla.csv', index_col=0)\n",
    "amazon.columns = ['amzn_' + col.lower() for col in amazon.columns]\n",
    "tesla.columns = ['tsla_' + col.lower() for col in tesla.columns]\n",
    "result = pd.concat([amazon, tesla], axis=1)\n",
    "quotations = result[['amzn_open', 'amzn_close', 'tsla_open', 'tsla_close']].copy()\n",
    "quotations['amzn_change'] = (quotations['amzn_close'] / quotations['amzn_open'] - 1) * 100\n",
    "quotations['tsla_change'] = (quotations['tsla_close'] / quotations['tsla_open'] - 1) * 100\n",
    "quotations['similarity_flag'] = (quotations['amzn_change'] * quotations['tsla_change'] > 0) * 1\n",
    "print(quotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55.00%\n"
     ]
    }
   ],
   "source": [
    "#EX-116:Calculate percentage of treding sessions for which amazon and tesla had same direction similarity_flag=1\n",
    " \n",
    "pd.set_option('display.max_columns', 30)\n",
    "pd.set_option('display.width', 1000)\n",
    " \n",
    "amazon = pd.read_csv('amazon.csv', index_col=0)\n",
    "tesla = pd.read_csv('tesla.csv', index_col=0)\n",
    "amazon.columns = ['amzn_' + col.lower() for col in amazon.columns]\n",
    "tesla.columns = ['tsla_' + col.lower() for col in tesla.columns]\n",
    "result = pd.concat([amazon, tesla], axis=1)\n",
    "quotations = result[['amzn_open', 'amzn_close', 'tsla_open', 'tsla_close']].copy()\n",
    "quotations['amzn_change'] = (quotations['amzn_close'] / quotations['amzn_open'] - 1) * 100\n",
    "quotations['tsla_change'] = (quotations['tsla_close'] / quotations['tsla_open'] - 1) * 100\n",
    "quotations['similarity_flag'] = (quotations['amzn_change'] * quotations['tsla_change'] > 0) * 1\n",
    "result = quotations['similarity_flag'].sum() / len(quotations)\n",
    "print(f'{result * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  product_id          name    price\n",
      "0        001  mobile phone  1490.00\n",
      "1        004        laptop  3400.00\n",
      "2        007         mouse    59.99\n",
      "3        010        tablet   999.00\n",
      "  order_id product_id  quantity\n",
      "0     1001        004         2\n",
      "1     1002        001         1\n",
      "2     1003        001         1\n",
      "3     1004        007         3\n",
      "  order_id product_id  quantity\n",
      "0     1005        010         2\n",
      "1     1006        001         1\n",
      "2     1007        007         1\n"
     ]
    }
   ],
   "source": [
    "#EX-117:Use this dictionaries for create dataframe products, orders_day_1, orders_day_2\n",
    "products_dict = {\n",
    "    'product_id': ['001', '004', '007', '010'],\n",
    "    'name': ['mobile phone', 'laptop', 'mouse', 'tablet'],\n",
    "    'price': [1490.0, 3400.0, 59.99, 999.00]\n",
    "}\n",
    " \n",
    "orders_day_1_dict = {\n",
    "    'order_id': ['1001', '1002', '1003', '1004'],\n",
    "    'product_id': ['004', '001', '001', '007'],\n",
    "    'quantity': [2, 1, 1, 3]\n",
    "}       \n",
    " \n",
    "orders_day_2_dict = {\n",
    "    'order_id': ['1005', '1006', '1007'],\n",
    "    'product_id': ['010', '001', '007'],\n",
    "    'quantity': [2, 1, 1]\n",
    "}                \n",
    " \n",
    "products = pd.DataFrame(products_dict)\n",
    "orders_day_1 = pd.DataFrame(orders_day_1_dict)\n",
    "orders_day_2 = pd.DataFrame(orders_day_2_dict)\n",
    " \n",
    "print(products)\n",
    "print(orders_day_1)\n",
    "print(orders_day_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  order_id product_id  quantity\n",
      "0     1001        004         2\n",
      "1     1002        001         1\n",
      "2     1003        001         1\n",
      "3     1004        007         3\n",
      "4     1005        010         2\n",
      "5     1006        001         1\n",
      "6     1007        007         1\n"
     ]
    }
   ],
   "source": [
    "#EX-118:Combine orders_day_1 dataframe with orders_day_2\n",
    "products_dict = {\n",
    "    'product_id': ['001', '004', '007', '010'],\n",
    "    'name': ['mobile phone', 'laptop', 'mouse', 'tablet'],\n",
    "    'price': [1490.0, 3400.0, 59.99, 999.00]\n",
    "}\n",
    " \n",
    "orders_day_1_dict = {\n",
    "    'order_id': ['1001', '1002', '1003', '1004'],\n",
    "    'product_id': ['004', '001', '001', '007'],\n",
    "    'quantity': [2, 1, 1, 3]\n",
    "}       \n",
    " \n",
    "orders_day_2_dict = {\n",
    "    'order_id': ['1005', '1006', '1007'],\n",
    "    'product_id': ['010', '001', '007'],\n",
    "    'quantity': [2, 1, 1]\n",
    "}                \n",
    " \n",
    "products = pd.DataFrame(products_dict)\n",
    "orders_day_1 = pd.DataFrame(orders_day_1_dict)\n",
    "orders_day_2 = pd.DataFrame(orders_day_2_dict)\n",
    " \n",
    "orders = orders_day_1.append(orders_day_2, ignore_index=True)\n",
    "print(orders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  order_id product_id  quantity          name    price\n",
      "0     1001        004         2        laptop  3400.00\n",
      "1     1002        001         1  mobile phone  1490.00\n",
      "2     1003        001         1  mobile phone  1490.00\n",
      "3     1006        001         1  mobile phone  1490.00\n",
      "4     1004        007         3         mouse    59.99\n",
      "5     1007        007         1         mouse    59.99\n",
      "6     1005        010         2        tablet   999.00\n"
     ]
    }
   ],
   "source": [
    "#EX-119:Create dataframe and assign it to result variable\n",
    " \n",
    "products_dict = {\n",
    "    'product_id': ['001', '004', '007', '010'],\n",
    "    'name': ['mobile phone', 'laptop', 'mouse', 'tablet'],\n",
    "    'price': [1490.0, 3400.0, 59.99, 999.00]\n",
    "}\n",
    " \n",
    "orders_day_1_dict = {\n",
    "    'order_id': ['1001', '1002', '1003', '1004'],\n",
    "    'product_id': ['004', '001', '001', '007'],\n",
    "    'quantity': [2, 1, 1, 3]\n",
    "}       \n",
    " \n",
    "orders_day_2_dict = {\n",
    "    'order_id': ['1005', '1006', '1007'],\n",
    "    'product_id': ['010', '001', '007'],\n",
    "    'quantity': [2, 1, 1]\n",
    "}                \n",
    " \n",
    "products = pd.DataFrame(products_dict)\n",
    "orders_day_1 = pd.DataFrame(orders_day_1_dict)\n",
    "orders_day_2 = pd.DataFrame(orders_day_2_dict)\n",
    "orders = orders_day_1.append(orders_day_2, ignore_index=True)\n",
    " \n",
    "result = pd.merge(orders, products, on='product_id')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  order_id product_id  quantity          name    price    total\n",
      "0     1001        004         2        laptop  3400.00  6800.00\n",
      "1     1002        001         1  mobile phone  1490.00  1490.00\n",
      "2     1003        001         1  mobile phone  1490.00  1490.00\n",
      "3     1006        001         1  mobile phone  1490.00  1490.00\n",
      "4     1004        007         3         mouse    59.99   179.97\n",
      "5     1007        007         1         mouse    59.99    59.99\n",
      "6     1005        010         2        tablet   999.00  1998.00\n"
     ]
    }
   ],
   "source": [
    "#EX-120:Based on the quantity and price column, calculate a new column total that stores totalamount for each column\n",
    "products_dict = {\n",
    "    'product_id': ['001', '004', '007', '010'],\n",
    "    'name': ['mobile phone', 'laptop', 'mouse', 'tablet'],\n",
    "    'price': [1490.0, 3400.0, 59.99, 999.00]\n",
    "}\n",
    " \n",
    "orders_day_1_dict = {\n",
    "    'order_id': ['1001', '1002', '1003', '1004'],\n",
    "    'product_id': ['004', '001', '001', '007'],\n",
    "    'quantity': [2, 1, 1, 3]\n",
    "}       \n",
    " \n",
    "orders_day_2_dict = {\n",
    "    'order_id': ['1005', '1006', '1007'],\n",
    "    'product_id': ['010', '001', '007'],\n",
    "    'quantity': [2, 1, 1]\n",
    "}                \n",
    " \n",
    "products = pd.DataFrame(products_dict)\n",
    "orders_day_1 = pd.DataFrame(orders_day_1_dict)\n",
    "orders_day_2 = pd.DataFrame(orders_day_2_dict)\n",
    "orders = orders_day_1.append(orders_day_2, ignore_index=True)\n",
    "result = pd.merge(orders, products, on='product_id')\n",
    " \n",
    "result['total'] = result['quantity'] * result['price']\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EX-121:result.csv ->skip index, result.html,result.json\n",
    "products_dict = {\n",
    "    'product_id': ['001', '004', '007', '010'],\n",
    "    'name': ['mobile phone', 'laptop', 'mouse', 'tablet'],\n",
    "    'price': [1490.0, 3400.0, 59.99, 999.00]\n",
    "}\n",
    " \n",
    "orders_day_1_dict = {\n",
    "    'order_id': ['1001', '1002', '1003', '1004'],\n",
    "    'product_id': ['004', '001', '001', '007'],\n",
    "    'quantity': [2, 1, 1, 3]\n",
    "}       \n",
    " \n",
    "orders_day_2_dict = {\n",
    "    'order_id': ['1005', '1006', '1007'],\n",
    "    'product_id': ['010', '001', '007'],\n",
    "    'quantity': [2, 1, 1]\n",
    "}                \n",
    " \n",
    "products = pd.DataFrame(products_dict)\n",
    "orders_day_1 = pd.DataFrame(orders_day_1_dict)\n",
    "orders_day_2 = pd.DataFrame(orders_day_2_dict)\n",
    "orders = orders_day_1.append(orders_day_2, ignore_index=True)\n",
    "result = pd.merge(orders, products, on='product_id')\n",
    "result['total'] = result['quantity'] * result['price']\n",
    " \n",
    "result.to_csv('result.csv', index=False)\n",
    "result.to_html('result.html')\n",
    "result.to_json('result.json', indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  emp_id first_name last_name dept_id dept_name\n",
      "0   1001       John     Smith     002     Sales\n",
      "1   1002       Mark      Cook     001        IT\n",
      "2   1003        Bob       Cat     001        IT\n"
     ]
    }
   ],
   "source": [
    "#EX-122:Make an inner join of employees and department \n",
    "employees = pd.DataFrame({\n",
    "    'emp_id': ['1001', '1002', '1003', '1004'],\n",
    "    'first_name': ['John', 'Mark', 'Bob', 'Alice'],\n",
    "    'last_name': ['Smith', 'Cook', 'Cat', 'Lee'],\n",
    "    'dept_id': ['002', '001', '001', '005']\n",
    "})\n",
    " \n",
    "departments = pd.DataFrame({\n",
    "    'dept_id': ['001', '002', '003', '004'],\n",
    "    'dept_name': ['IT', 'Sales', 'Marketing', 'Support']\n",
    "})\n",
    " \n",
    "result = pd.merge(employees, departments, how='inner', on='dept_id')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  emp_id first_name last_name dept_id dept_name\n",
      "0   1001       John     Smith     002     Sales\n",
      "1   1002       Mark      Cook     001        IT\n",
      "2   1003        Bob       Cat     001        IT\n",
      "3   1004      Alice       Lee     005       NaN\n"
     ]
    }
   ],
   "source": [
    "#EX-123:Make an Left join of employees and department \n",
    "employees = pd.DataFrame({\n",
    "    'emp_id': ['1001', '1002', '1003', '1004'],\n",
    "    'first_name': ['John', 'Mark', 'Bob', 'Alice'],\n",
    "    'last_name': ['Smith', 'Cook', 'Cat', 'Lee'],\n",
    "    'dept_id': ['002', '001', '001', '005']\n",
    "})\n",
    " \n",
    "departments = pd.DataFrame({\n",
    "    'dept_id': ['001', '002', '003', '004'],\n",
    "    'dept_name': ['IT', 'Sales', 'Marketing', 'Support']\n",
    "})\n",
    " \n",
    "result = pd.merge(employees, departments, how='left', on='dept_id')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  emp_id first_name last_name dept_id  dept_name\n",
      "0   1002       Mark      Cook     001         IT\n",
      "1   1003        Bob       Cat     001         IT\n",
      "2   1001       John     Smith     002      Sales\n",
      "3    NaN        NaN       NaN     003  Marketing\n",
      "4    NaN        NaN       NaN     004    Support\n"
     ]
    }
   ],
   "source": [
    "#EX-124:Make an Right join of employees and department \n",
    "employees = pd.DataFrame({\n",
    "    'emp_id': ['1001', '1002', '1003', '1004'],\n",
    "    'first_name': ['John', 'Mark', 'Bob', 'Alice'],\n",
    "    'last_name': ['Smith', 'Cook', 'Cat', 'Lee'],\n",
    "    'dept_id': ['002', '001', '001', '005']\n",
    "})\n",
    " \n",
    "departments = pd.DataFrame({\n",
    "    'dept_id': ['001', '002', '003', '004'],\n",
    "    'dept_name': ['IT', 'Sales', 'Marketing', 'Support']\n",
    "})\n",
    " \n",
    "result = pd.merge(employees, departments, how='right', on='dept_id')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  emp_id first_name last_name dept_id  dept_name\n",
      "0   1001       John     Smith     002      Sales\n",
      "1   1002       Mark      Cook     001         IT\n",
      "2   1003        Bob       Cat     001         IT\n",
      "3   1004      Alice       Lee     005        NaN\n",
      "4    NaN        NaN       NaN     003  Marketing\n",
      "5    NaN        NaN       NaN     004    Support\n"
     ]
    }
   ],
   "source": [
    "#EX-125:Make an Outer join of employees and department \n",
    "employees = pd.DataFrame({\n",
    "    'emp_id': ['1001', '1002', '1003', '1004'],\n",
    "    'first_name': ['John', 'Mark', 'Bob', 'Alice'],\n",
    "    'last_name': ['Smith', 'Cook', 'Cat', 'Lee'],\n",
    "    'dept_id': ['002', '001', '001', '005']\n",
    "})\n",
    " \n",
    "departments = pd.DataFrame({\n",
    "    'dept_id': ['001', '002', '003', '004'],\n",
    "    'dept_name': ['IT', 'Sales', 'Marketing', 'Support']\n",
    "})\n",
    " \n",
    "result = pd.merge(employees, departments, how='outer', on='dept_id')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  emp_id first_name last_name dept_id dept_name\n",
      "0   1001       John     Smith     002     Sales\n",
      "1   1002       Mark      Cook     001        IT\n",
      "2   1003        Bob       Cat     001        IT\n",
      "3   1003        Bob       Cat     001        IT\n"
     ]
    }
   ],
   "source": [
    "#EX-126: We have duplicate values using inner join\n",
    "employees = pd.DataFrame({\n",
    "    'emp_id': ['1001', '1002', '1003', '1003', '1004'],\n",
    "    'first_name': ['John', 'Mark', 'Bob', 'Bob', 'Alice'],\n",
    "    'last_name': ['Smith', 'Cook', 'Cat', 'Cat', 'Lee'],\n",
    "    'dept_id': ['002', '001', '001', '001', '005']\n",
    "})\n",
    "\n",
    "departments = pd.DataFrame({\n",
    "    'dept_id': ['001', '002', '003', '004'],\n",
    "    'dept_name': ['IT', 'Sales', 'Marketing', 'Support']\n",
    "})\n",
    "\n",
    "result = pd.merge(employees, departments, how='inner', on='dept_id')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  emp_id first_name last_name dept_id dept_name\n",
      "0   1001       John     Smith     002     Sales\n",
      "1   1002       Mark      Cook     001        IT\n",
      "2   1003        Bob       Cat     001        IT\n"
     ]
    }
   ],
   "source": [
    "#EX-127:Remove the duplicates from employee dataframe and assign them to employee_unique variable\n",
    "employees = pd.DataFrame({\n",
    "    'emp_id': ['1001', '1002', '1003', '1003', '1004'],\n",
    "    'first_name': ['John', 'Mark', 'Bob', 'Bob', 'Alice'],\n",
    "    'last_name': ['Smith', 'Cook', 'Cat', 'Cat', 'Lee'],\n",
    "    'dept_id': ['002', '001', '001', '001', '005']\n",
    "})\n",
    "\n",
    "departments = pd.DataFrame({\n",
    "    'dept_id': ['001', '002', '003', '004'],\n",
    "    'dept_name': ['IT', 'Sales', 'Marketing', 'Support']\n",
    "})\n",
    "\n",
    "employees_unique = employees.drop_duplicates()\n",
    "result = pd.merge(employees_unique, departments, how='inner', on='dept_id')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           tip  total_bill\n",
      "day                       \n",
      "Fri   2.734737   17.151579\n",
      "Sat   2.993103   20.441379\n",
      "Sun   3.255132   21.410000\n",
      "Thur  2.771452   17.682742\n"
     ]
    }
   ],
   "source": [
    "#EX-128: Using pivot table prepare dataframe. Average value of the tip and total_bill columns broken into days\n",
    "pd.set_option('display.max_columns', 30)\n",
    "pd.set_option('display.width', 1000)\n",
    "tips = pd.read_csv('https://raw.githubusercontent.com/mwaskom/seaborn-data/master/tips.csv')\n",
    "result = pd.pivot_table(tips, index='day', values=['tip', 'total_bill'], aggfunc=np.mean)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  tip  total_bill\n",
      "day  sex                         \n",
      "Fri  Female  2.781111   14.145556\n",
      "     Male    2.693000   19.857000\n",
      "Sat  Female  2.801786   19.680357\n",
      "     Male    3.083898   20.802542\n",
      "Sun  Female  3.367222   19.872222\n",
      "     Male    3.220345   21.887241\n",
      "Thur Female  2.575625   16.715312\n",
      "     Male    2.980333   18.714667\n"
     ]
    }
   ],
   "source": [
    "#EX-129:Using pivot table prepare dataframe. Average value of the tip and total_bill columns broken into days, gender\n",
    "pd.set_option('display.max_columns', 30)\n",
    "pd.set_option('display.width', 1000)\n",
    "tips = pd.read_csv('https://raw.githubusercontent.com/mwaskom/seaborn-data/master/tips.csv')\n",
    "result = pd.pivot_table(tips, index=['day', 'sex'], values=['tip', 'total_bill'], aggfunc=np.mean)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        tip  total_bill\n",
      "day                    \n",
      "Fri    4.73       40.17\n",
      "Sat   10.00       50.81\n",
      "Sun    6.50       48.17\n",
      "Thur   6.70       43.11\n"
     ]
    }
   ],
   "source": [
    "#EX-130:Using pivot table prepare dataframe. Maximum value of the tip and total_bill columns broken into days, gender\n",
    "\n",
    "pd.set_option('display.max_columns', 30)\n",
    "pd.set_option('display.width', 1000)\n",
    "tips = pd.read_csv('https://raw.githubusercontent.com/mwaskom/seaborn-data/master/tips.csv')\n",
    "result = pd.pivot_table(tips, index='day', values=['tip', 'total_bill'], aggfunc=np.max)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         tip  total_bill\n",
      "day  sex    smoker                      \n",
      "Fri  Female No      3.125000   19.365000\n",
      "            Yes     2.682857   12.654286\n",
      "     Male   No      2.500000   17.475000\n",
      "            Yes     2.741250   20.452500\n",
      "Sat  Female No      2.724615   19.003846\n",
      "            Yes     2.868667   20.266667\n",
      "     Male   No      3.256563   19.929063\n",
      "            Yes     2.879259   21.837778\n",
      "Sun  Female No      3.329286   20.824286\n",
      "            Yes     3.500000   16.540000\n",
      "     Male   No      3.115349   20.403256\n",
      "            Yes     3.521333   26.141333\n",
      "Thur Female No      2.459600   16.014400\n",
      "            Yes     2.990000   19.218571\n",
      "     Male   No      2.941500   18.486500\n",
      "            Yes     3.058000   19.171000\n"
     ]
    }
   ],
   "source": [
    "#EX-131:Using pivot table prepare dataframe. Average value of the tip and total_bill columns broken into days, gender, smoker/non-smoker\n",
    "pd.set_option('display.max_columns', 30)\n",
    "pd.set_option('display.width', 1000)\n",
    "tips = pd.read_csv('https://raw.githubusercontent.com/mwaskom/seaborn-data/master/tips.csv')\n",
    " \n",
    "result = pd.pivot_table(tips, index=['day', 'sex', 'smoker'], values=['tip', 'total_bill'], aggfunc=np.mean)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    tip  total_bill\n",
      "sex    smoker                      \n",
      "Female No      3.329286   20.824286\n",
      "       Yes     3.500000   16.540000\n",
      "Male   No      3.115349   20.403256\n",
      "       Yes     3.521333   26.141333\n"
     ]
    }
   ],
   "source": [
    "#EX-132: Extract value for sunday\n",
    "pd.set_option('display.max_columns', 30)\n",
    "pd.set_option('display.width', 1000)\n",
    "tips = pd.read_csv('https://raw.githubusercontent.com/mwaskom/seaborn-data/master/tips.csv')\n",
    " \n",
    "result = pd.pivot_table(tips, index=['day', 'sex', 'smoker'], values=['tip', 'total_bill'], aggfunc=np.mean)\n",
    "print(result.loc['Sun'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             tip  total_bill\n",
      "smoker                      \n",
      "No      3.115349   20.403256\n",
      "Yes     3.521333   26.141333\n"
     ]
    }
   ],
   "source": [
    "#EX-133:Extract value for sunday and men from this dataframe\n",
    "pd.set_option('display.max_columns', 30)\n",
    "pd.set_option('display.width', 1000)\n",
    "tips = pd.read_csv('https://raw.githubusercontent.com/mwaskom/seaborn-data/master/tips.csv')\n",
    "result = pd.pivot_table(tips, index=['day', 'sex', 'smoker'], values=['tip', 'total_bill'], aggfunc=np.mean)\n",
    "print(result.loc['Sun'].loc['Male'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
